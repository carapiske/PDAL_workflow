{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "797f557e-435f-49cd-8002-2135758b8c67",
   "metadata": {},
   "source": [
    "Fall 2021<br>\n",
    "Modified from Theo Hartsook from NRES 782 <br>\n",
    "Goal: create JSON pipelines to save las files <br>\n",
    "\n",
    "See: http://www.asprs.org/wp-content/uploads/2019/07/LAS_1_4_r15.pdf page 19 for classification information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704551bb-6e47-4c22-94d3-17ecd020e91a",
   "metadata": {},
   "source": [
    "**ASPRS Standard Point Classes (Point Data Record Formats 6-10):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d24c11a-f3b9-4d59-a4a0-7e84f03d19d2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "0 Created, Never Classified See note4 <br>\n",
    "1 Unclassified<br>\n",
    "2 Ground<br>\n",
    "3 Low Vegetation<br>\n",
    "4 Medium Vegetation<br>\n",
    "5 High Vegetation<br>\n",
    "6 Building<br>\n",
    "7 Low Point (Noise)<br>\n",
    "8 Reserved<br>\n",
    "9 Water<br>\n",
    "10 Rail<br>\n",
    "11 Road Surface<br>\n",
    "12 Reserved<br>\n",
    "13 Wire – Guard (Shield)<br>\n",
    "14 Wire – Conductor (Phase)<br>\n",
    "15 Transmission Tower<br>\n",
    "16 Wire-Structure Connector e.g., insulators<br>\n",
    "17 Bridge Deck<br>\n",
    "18 High Noise<br>\n",
    "19 Overhead Structure e.g., conveyors, mining equipment, traffic\n",
    "lights<br>\n",
    "20 Ignored Ground e.g., breakline proximity<br>\n",
    "21 Snow<br>\n",
    "22 Temporal Exclusion Features excluded due to changes over\n",
    "time between data sources – e.g., water\n",
    "levels, landslides, permafrost<br>\n",
    "23-63 Reserved<br>\n",
    "64-255 User Definable<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ef19ecac-1150-469a-9a3f-3eb6f8b1c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary files\n",
    "\n",
    "import json # where we will save the json files to run a pipeline\n",
    "import os \n",
    "import subprocess # allows us to run command line commands\n",
    "import pdal\n",
    "os.chdir('/Volumes/cpiske')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cb3e5234-2041-4632-b4fa-e043a256b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test docker\n",
    "# sudo docker run -v /Users/carapiske/Desktop/test_las:/input pdal/pdal touch /input/hey.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436eea6-1aef-403f-a7be-0d4195cbdd8f",
   "metadata": {},
   "source": [
    "## Get info\n",
    "Generally, we can either use our local pdal package or pull from a docker image. We'll practice both below but prefer the docker method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1bd070bb-1da4-4689-bd04-755e0eb7cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a test file (in this case: /mcc_part_b_tile_004_000.las)\n",
    "input_path = '/Volumes/cpiske/lidar_processing/python_scripts/PDAL/test_las' # define input las path (not filename)\n",
    "input_las = 'lidar_processing/python_scripts/PDAL/test_las/ncalm_2014_732000_4373000.las' # define input las full file path\n",
    "\n",
    "input_path_docker = input_path + ':/input'\n",
    "input_las_docker = '/input/'+'ncalm_2014_732000_4373000.las'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c62765df-4543-4b80-be76-259bb530efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdal_info_command = ['pdal', 'info', 'lidar_processing/python_scripts/PDAL/test_las/ASO_USCAMB20180425f1a1_180425_1_dem_filter.las']\n",
    "pdal_info_command_Docker = ['docker', 'run', '-v', input_path_docker, 'pdal/pdal', 'pdal', 'info', input_las_docker]\n",
    "pda_metadata_command = ['pdal', 'info', input_las, '--metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c24a51df-0a74-4628-8c16-bdaa094c1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # terminal command using docker\n",
    "# subprocess.run(['docker', 'run', '-v', '/Users/carapiske/Desktop/test_las:/input', 'pdal/pdal', 'pdal', 'info', '/input/mcc_part_b_tile_004_000.las'])\n",
    "# # or \n",
    "# subprocess.run(pdal_info_command_Docker)\n",
    "# # or use local pdal\n",
    "# subprocess.run(pdal_info_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d616bf6-1355-4d4c-a0c4-9ff4aee6f4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be10eab7-1dc5-4561-9ff8-dbabb55abf57",
   "metadata": {},
   "source": [
    "## Convert .las to .txt\n",
    "see: https://pdal.io/stages/writers.text.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "069497d0-a99b-4952-bfa2-3af3d3c0ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up json file commands\n",
    "output_txt = '/Volumes/cpiske/lidar_processing/python_scripts/PDAL/test_las/mcc_part_b_tile_004_000Test.asc'\n",
    "output_json = 'lidar_processing/python_scripts/PDAL/JSON/las_to_txt.json'\n",
    "\n",
    "# create a pipeline and save to a json file \n",
    "\n",
    "filter_dict = {'type':'readers.las',\n",
    "               'override_srs': \"EPSG:4326\",\n",
    "              'filename': input_las} # we are reading in a las file\n",
    "rasterize_dict = {'type':'writers.las',\n",
    "'format':'geojson',\n",
    "'order':'X,Y,Z',\n",
    "'keep_unspecified':'false',\n",
    "'filename':output_txt}\n",
    "\n",
    "\n",
    "pipeline_list = [filter_dict, rasterize_dict]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(output_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f570972-2f18-40d1-b4d2-06f0ed5ec7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "proj_create_from_database: crs not found\n",
      "proj_create_from_database: crs not found\n",
      "proj_uom_get_info_from_database: unit of measure not found\n",
      "proj_create_from_database: crs not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['pdal', 'pipeline', 'lidar_processing/python_scripts/PDAL/JSON/las_to_txt.json'], returncode=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_path = 'lidar_processing/python_scripts/PDAL/JSON/las_to_txt.json'\n",
    "pdal_commands = ['pdal', 'pipeline', json_path]\n",
    "subprocess.run(pdal_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a3a30-1ae6-481b-96ac-f95a1f6f4ddc",
   "metadata": {},
   "source": [
    "### .laz to .las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "efe33f9e-84de-49ea-a538-0cd37b7f7877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up json file commands\n",
    "input_laz = 'lidar_processing/python_scripts/PDAL/test_las/ASO_USCAMB20180425f1a1_180425_1_dem_filter.laz'\n",
    "output_las = 'lidar_processing/python_scripts/PDAL/test_las/ASO_USCAMB20180425f1a1_180425_1_dem_filter.las'\n",
    "output_json = 'lidar_processing/python_scripts/PDAL/JSON/laz_to_las.json'\n",
    "\n",
    "# create a pipeline and save to a json file \n",
    "\n",
    "filter_dict = {'type':'readers.las',\n",
    "               'filename': input_las} # we are reading in a las file\n",
    "translate_dict = {'type':'writers.las',\n",
    "                  \"a_srs\": \"EPSG:4326\",\n",
    "                  'filename':output_las}\n",
    "\n",
    "\n",
    "pipeline_list = [filter_dict, translate_dict]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(output_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "efe40151-4f3c-4fc8-acc0-ff2e092d788b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['pdal', 'pipeline', 'lidar_processing/python_scripts/PDAL/JSON/laz_to_las.json'], returncode=0)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_path = 'lidar_processing/python_scripts/PDAL/JSON/laz_to_las.json'\n",
    "pdal_commands = ['pdal', 'pipeline', json_path]\n",
    "subprocess.run(pdal_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3608299f-146c-46d5-84bf-2e4d9425eb40",
   "metadata": {},
   "source": [
    "## Ground Filter Tutorial\n",
    "Modified from https://pdal.io/tutorial/ground-filters.html <br>\n",
    "Bradley Chambers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0f306f0e-626c-4710-b4af-437e12e9ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json = 'lidar_processing/python_scripts/PDAL/JSON/ground_filter_tutorial.json'\n",
    "input_las = 'lidar_processing/python_scripts/PDAL/test_las/mcc_part_b_tile_002_004_reproj.las' # define input las full file path\n",
    "output_las = 'lidar_processing/python_scripts/PDAL/test_las/mcc_part_b_tile_002_004_reproj_GFtutorial.las' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3a1c3714-9583-458e-9b08-f8fbe7b257c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name JSON file\n",
    "output_json = 'lidar_processing/python_scripts/PDAL/JSON/ground_filter_tutorial.json'\n",
    "# input_las = 'lidar_processing/python_scripts/PDAL/test_las/mcc_part_b_tile_004_000.las' # define input las full file path\n",
    "# output_las = 'lidar_processing/python_scripts/PDAL/test_las/mcc_part_b_tile_004_000_GFtutorial.las' # define input las full file path\n",
    "\n",
    "# create a pipeline and save to a json file \n",
    "last_val = True\n",
    "filter_dict_reproj = {'type':'filters.reprojection', #PDAL’s default parameters are specified in meters, and individual filter stages typically assume that units are at least uniform in X, Y, and Z. Because data will not always be provided in this way, PDAL pipelines should account for any data reprojections and parameter scaling that are required from one dataset to the next\n",
    "                      'in_srs':'EPSG:4326',\n",
    "                      'out_srs': \"EPSG:4326\",}\n",
    "filter_dict_assign = {'type':'filters.assign',\n",
    "                      \"assignment\":\"Classification[:]=0\"}\n",
    "filter_dict_elm = {'type':'filters.elm'} # identify low noise points that can adversely affect ground segmentation algorithms\n",
    "filter_dict_outlier = {'type':'filters.outlier'} #  two methods of outlier detection at the moment: radius and statistical. Both aim to identify points that are isolated and likely arise from noise sources.\n",
    "filter_dict_smrf = {\"type\":\"filters.smrf\", # \n",
    "                    \"ignore\":\"Classification[7:7]\",\n",
    "                    \"slope\":0.2,\n",
    "                    \"window\":16,\n",
    "                    \"threshold\":0.15,\n",
    "                    \"scalar\":1.2}\n",
    "filter_dict_range = {\"type\":\"filters.range\",\n",
    "                    \"limits\":\"Classification[2:2]\"}\n",
    "output_las = \"lidar_processing/python_scripts/PDAL/test_las/ncalm_2014_732000_4373000_GFtutorial.las\"\n",
    "\n",
    "\n",
    "pipeline_list = [filter_dict_reproj,filter_dict_assign,filter_dict_elm, filter_dict_outlier, filter_dict_smrf, filter_dict_range]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(output_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "72aa2cbe-3e21-4a22-918e-2da81451d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_tutorial_command = ['pdal', 'translate', input_las, output_las, '--json', 'lidar_processing/python_scripts/PDAL/JSON/ground_filter_tutorial.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cc668165-6065-417a-8496-36077246f227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['pdal', 'translate', 'lidar_processing/python_scripts/PDAL/test_las/ncalm_2014_732000_4373000.las', 'lidar_processing/python_scripts/PDAL/test_las/ncalm_2014_732000_4373000_GFtutorial.las', '--json', 'lidar_processing/python_scripts/PDAL/JSON/ground_filter_tutorial.json'], returncode=0)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(gf_tutorial_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597edf1-6d46-4850-ac9c-fe5d127ccaa9",
   "metadata": {},
   "source": [
    "## Create DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc512a-97e9-4282-bceb-9ae5e216a729",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"pipeline\": [\n",
    "        \"./exercises/analysis/ground/denoised-ground-only.laz\",\n",
    "        {\n",
    "            \"filename\":\"./exercises/analysis/dtm/dtm.tif\",\n",
    "            \"gdaldriver\":\"GTiff\",\n",
    "            \"output_type\":\"all\",\n",
    "            \"resolution\":\"2.0\",\n",
    "            \"type\": \"writers.gdal\"\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e6caa9-6398-4bf8-a45c-553e0b6fbd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name JSON file\n",
    "output_json = 'lidar_processing/python_scripts/PDAL/JSON/las_to_dtm.json'\n",
    "# input_las = 'lidar_processing/python_scripts/PDAL/test_las/mcc_part_b_tile_004_000.las' # define input las full file path\n",
    "# output_las = 'lidar_processing/python_scripts/PDAL/test_las/mcc_part_b_tile_004_000_GFtutorial.las' # define input las full file path\n",
    "\n",
    "# create a pipeline and save to a json file \n",
    "filter_gdal= {'gdaldriver':'GTiff',\n",
    "              'output_type': \"all\",}\n",
    "output_dtm = \"lidar_processing/python_scripts/PDAL/test_file/ncalm_2014_732000_4373000_DTMtutorial.tif\"\n",
    "\n",
    "\n",
    "pipeline_list = [filter_gdal]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(output_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd2d4ef-b5e5-4182-8148-d014cf3eb22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7cd6d1-131b-4f45-82b5-f48c050d850d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b38f3-9fe8-4ff7-86b1-68ec585bc56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0fe287-69ba-461b-b7fb-6b662e2bbff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84755a16-6c56-4a92-839f-5f6d09e1bf44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e59bbf-89a9-4731-9442-419018c7b00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef95aabd-bd70-47a0-be17-993b89088961",
   "metadata": {},
   "source": [
    "# Theo Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "784a85fc-2834-4d0d-81a9-19f790b08678",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_las = 'SCB/kost_lidar_data/ASO_2016/2016_05_18/WGS84_G1762_to_NAD83_NAVD88/mcc_part_b_tile_004_000.las'\n",
    "\n",
    "z_min = 0.15\n",
    "z_max = 2\n",
    "z_range = 'Z[' + str(z_min) + ':' + str(z_max) + ']'\n",
    "output_raster = 'lidar_processing/python_scripts/PDAL/test_file/mcc_part_b_tile_004_000.tif'\n",
    "output_json = 'lidar_processing/python_scripts/PDAL/JSON/las_to_tif.json'\n",
    "resolution = 0.01\n",
    "\n",
    "filter_dict = {'type':'filters.range', 'limits':z_range}\n",
    "rasterize_dict = {'filename':output_raster,\n",
    "'gdaldriver':'GTiff',\n",
    "'output_type':'count',\n",
    "'resolution':resolution,\n",
    "'type': 'writers.gdal'}\n",
    "\n",
    "\n",
    "pipeline_list = [input_las, filter_dict, rasterize_dict]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(output_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1929f364-00c7-482e-8d5f-537652eed3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_las = 'SCB/kost_lidar_data/ASO_2016/2016_05_18/WGS84_G1762_to_NAD83_NAVD88/mcc_part_b_tile_004_000.las'\n",
    "\n",
    "# z_min = 0.15\n",
    "# z_max = 2\n",
    "# z_range = 'Z[' + str(z_min) + ':' + str(z_max) + ']'\n",
    "output_raster = 'lidar_processing/python_scripts/PDAL/test_file/mcc_part_b_tile_004_000.asc'\n",
    "output_json = 'lidar_processing/python_scripts/PDAL/JSON/las_to_asc.json'\n",
    "resolution = 0.01\n",
    "\n",
    "filter_dict = {'type':'filters.range', 'limits':z_range}\n",
    "rasterize_dict = {'filename':output_raster,\n",
    "'gdaldriver':'XYZ',\n",
    "'output_type':'count',\n",
    "'resolution':resolution,\n",
    "'type': 'writers.gdal'}\n",
    "\n",
    "\n",
    "pipeline_list = [input_las, filter_dict, rasterize_dict]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(output_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4f6338-edab-4c85-8941-b05d63584dd8",
   "metadata": {},
   "source": [
    "sudo docker run -v path_to_laz_folder:/input 0b pdal info /input/test.laz\n",
    "\n",
    "where path_to_laz_folder is the path to the LAS/LAZ file (you just need the folder path, not the file path).\n",
    "\n",
    ":/input is the new folder that will be created in your Docker container that will hold your point cloud.\n",
    "\n",
    "0b is just the image id of pdal\n",
    "\n",
    "/input/test.laz is the path to the point cloud in the Docker container.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a941783e-828f-4226-a25a-b772a51d12d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_laz_folder = 'lidar_processing/python_scripts/PDAL/test_las'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee8f9b-8d85-490a-a3cd-22d4b06bb646",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo docker run -v path_to_laz_folder:/input 0b pdal info /input/test.laz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac352849-3336-4cd7-b7d4-2f0c2a2c79fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import pdal\n",
    "\n",
    "def assemblePipeline(input_las, list_of_dicts):\n",
    "    pipeline_list = [input_las]\n",
    "    pipeline_list.extend(list_of_dicts)\n",
    "    pipeline_dict = {'pipeline' : pipeline_list}\n",
    "    return pipeline_dict\n",
    "\n",
    "def makeHeightFilter(height, buffer):\n",
    "    z_min = height - buffer/2\n",
    "    z_max = height + buffer/2\n",
    "    z_range = 'Z[' + str(z_min) + ':' + str(z_max) + ']'\n",
    "    heightDict = {'type':'filters.range', 'limits':z_range}\n",
    "    return heightDict\n",
    "\n",
    "def makeRasterizeFilter(output_raster, resolution, epsg):\n",
    "    rasterize_dict = {'filename':output_raster,\n",
    "                      'gdaldriver':'GTiff',\n",
    "                      'output_type':'count',\n",
    "                      'resolution':resolution,\n",
    "                      'override_srs' : epsg,\n",
    "                      'type': 'writers.gdal'}\n",
    "    return rasterize_dict\n",
    "\n",
    "def convertTifForPIL(input_raster, output_raster, epsg):\n",
    "    ''' GDAL bindings are an alien concept to me, so I gave up and used\n",
    "        subprocess.'''\n",
    "    commands = ['gdal_translate', input_raster, output_raster, '-ot', 'Byte', '-a_srs', epsg]\n",
    "    subprocess.run(commands)\n",
    "\n",
    "\n",
    "def buildHeightSlice(input_las, height, buffer, output_raster, resolution, epsg, json_path=None):\n",
    "    filter_dict = makeHeightFilter(height, buffer)\n",
    "    rasterize_dict = makeRasterizeFilter(output_raster, resolution, epsg)\n",
    "    filter_list = [filter_dict, rasterize_dict]\n",
    "    pipeline_dict = assemblePipeline(input_las, filter_list)\n",
    "\n",
    "    if json_path is not None:\n",
    "        with open(json_path, 'w') as out:\n",
    "            json.dump(pipeline_dict, out, indent=4)\n",
    "        pdal_commands = ['pdal', 'pipeline', json_path]\n",
    "        subprocess.run(pdal_commands)\n",
    "    else:\n",
    "        pdal_commands = json.dumps(pipeline_dict)\n",
    "        pipeline = pdal.Pipeline(pdal_commands)\n",
    "        pipeline.execute()\n",
    "\n",
    "input_las = '/Users/theo/data/las/TLS_0244_20180612_01_v003_30m_clip_height_norm.las'\n",
    "height = 1.37\n",
    "buffer = 0.05\n",
    "z_min = height - buffer/2\n",
    "z_max = height + buffer/2\n",
    "z_range = 'Z[' + str(z_min) + ':' + str(z_max) + ']'\n",
    "temp_raster = '/Users/theo/Pictures/almost_cool.tif'\n",
    "final_raster = '/Users/theo/Pictures/cool.tif'\n",
    "resolution = 0.01\n",
    "epsg = 'EPSG:3310'\n",
    "\n",
    "buildHeightSlice(input_las, height, buffer, temp_raster, resolution, epsg)\n",
    "convertTifForPIL(temp_raster, final_raster, epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d188910-a9a7-4c6c-b164-8a163c1d5445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import pdal\n",
    "import argparse\n",
    "\n",
    "# Create flags for the user to utilize.\n",
    "parser = argparse.ArgumentParser(description=\"Generate JSON pipeline to generate DTM from a point cloud.\")\n",
    "      \n",
    "required = parser.add_argument_group('Required arguments')\n",
    "required.add_argument('-crs', '--coordinate_system', required=True, action='store', help=\"EPSG code.\")\n",
    "required.add_argument('-i', '--infile', required=True, action='store', help=\"Input path to point cloud\")\n",
    "required.add_argument('-o', '--outfile', required=True, action='store', help=\"Output path.\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "def generateJSON(infile, list_of_dicts):\n",
    "    pipeline_list = [infile]\n",
    "    pipeline_list.extend(list_of_dicts)\n",
    "    pipeline_dict = {'pipeline': pipeline_list}\n",
    "    with open(\"pipeline.json\", 'w') as out:\n",
    "        json.dump(pipeline_dict, out, indent=4)\n",
    "\n",
    "def generateDTM(epsg, infile, outfile):\n",
    "    reproject_dict = {\"type\": \"filters.reprojection\",\n",
    "                      \"out_srs\": \"EPSG:{}\".format(epsg)}\n",
    "    reclassify_zero_dict = {\"type\": \"filters.assign\",\n",
    "                       \"assignment\": \"Classification[:]=0\"}\n",
    "    elm_dict = {\"type\": \"filters.elm\"}\n",
    "    outlier_dict = {\"type\": \"filters.outlier\"}\n",
    "    smrf_dict = {\"type\": \"filters.smrf\", \"ignore\": \"Classification[7:7]\",\n",
    "                 \"slope\": 0.2, \"window\": 16, \"threshold\": 0.45, \"scalar\": 1.2}\n",
    "    range_dict = {\"type\":\"filters.range\", \"limits\":\"Classification[2:2]\"}\n",
    "    output_dict = {\"filename\": outfile, \"gdaldriver\": \"GTiff\", \"output_type\": \"all\", \"resolution\": 0.01, \"type\": \"writers.gdal\"}\n",
    "    list_of_dicts = list([reproject_dict, reclassify_zero_dict, elm_dict, outlier_dict, smrf_dict, range_dict, output_dict])\n",
    "    generateJSON(infile, list_of_dicts)\n",
    "    pdal_cmds = ['pdal', 'pipeline', 'pipeline.json']\n",
    "    subprocess.run(pdal_cmds)\n",
    "    \n",
    "generateDTM(args.coordinate_system, args.infile, args.outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
