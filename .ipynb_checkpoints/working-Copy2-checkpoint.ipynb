{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a4dffb-88af-4fac-b934-cec5677c7c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7008cc52-bdcc-45fe-925a-d62844700ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary files\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import json # where we will save the json files to run a pipeline\n",
    "import os # for file management\n",
    "import subprocess # allows us to run command line commands\n",
    "import pdal # lidar processing package\n",
    "import rasterio\n",
    "import pyproj\n",
    "from osgeo import gdal\n",
    "\n",
    "import time\n",
    "# packages to copy files\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import glob\n",
    "# packages to extract wkt from polygon\n",
    "import shapefile\n",
    "import pygeoif\n",
    "# for parallel processing\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "import csv\n",
    "\n",
    "import re\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "#import seaborn as sns\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import kde\n",
    "from scipy.stats import gaussian_kde\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# See lidar_functions.py\n",
    "import lidar_functions\n",
    "pdal_pipeline = 'C:\\\\Users\\cpiske\\.conda\\envs\\lidar\\Lib\\site-packages\\pdal\\pipeline.py'\n",
    "gdal_merge = os.path.join('C:\\\\','Users','cpiske','.conda','envs','lidar','Lib','site-packages','osgeo_utils','gdal_merge.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442cccf2-3666-48e0-b86b-e684e3100730",
   "metadata": {},
   "source": [
    "Note that many functions are dependent on specific directory structures. See README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8504626a-f885-4371-8e25-b3bcff1d953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_base_path = 'piske_processing/PDAL_workflow/JSON/' # set so that we can redefine json across operating systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68613ba4-e486-475c-8667-a3e68ebc3196",
   "metadata": {},
   "source": [
    "Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ab5f30b-adf1-49d1-a3d7-904ff0a0d005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set current working directory\n",
    "path = '/'\n",
    "os.chdir(path)\n",
    "os.getcwd() # print to ensure we're in the right directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0711e077-2779-49de-9284-4c77056e8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_base_path = 'piske_processing/PDAL_workflow/JSON/' # set so that we can redefine json across operating systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ee45b96-9b13-48e7-99ea-b6b412347432",
   "metadata": {},
   "outputs": [],
   "source": [
    "writers_bounds = '([268000,286512.9],[4165234.9,4179857.7])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d54e01c6-5dc2-442d-addd-51916886e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input file\n",
    "input_lid = input_list[0]\n",
    "pdal_info_cmd = ['pdal','info',input_lid] # general info\n",
    "pdal_metadata_cmd = ['pdal','info',input_lid,'--metadata'] # full file metadata, including details crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92c4119a-5c11-4c0c-ada7-1e23491640e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdal_info_results = subprocess.run(pdal_metadata_cmd, stdout = subprocess.PIPE) # stout (standard out), PIPE indicates that a new pipe to the child should be created\n",
    "pdal_info_dict = json.loads(pdal_info_results.stdout.decode()) # create dict with metadata info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a406e3-c47b-4b18-a9c6-27ebd406137b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a546d8-5473-4714-9e87-b9d10e2f795c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "885c9673-3fe0-4a1c-b53b-30b7e1cc88ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_json = json_base_path+'count_from_las2.json' # define path to json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1503d7b9-0a35-45f0-9d41-189b1382987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'MRB/Merced_lidar/Watershed_Sciences/WSI_MRB_20111017/NAD83_NAD83_epoch2010/'\n",
    "output_tif = 'MRB/Merced_lidar/Watershed_Sciences/WSI_MRB_20111017/counts/WSI_MRB_20111017_counts_150200.tif'\n",
    "onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "input_list = [input_path + s for s in onlyfiles[150:200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7662be38-42d0-4e42-8642-8872ee310c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a185f281-86c3-4bce-aae7-60c4b5f382d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_dict = {}\n",
    "tags = ['']*len(input_list)\n",
    "filenames = ['']*len(input_list)\n",
    "for i in range(len(input_list)):\n",
    "    filename_dict['filename_'+str(i)] = {'filename':input_list[i], 'tag':'A_'+str(i)}\n",
    "    tags[i] = 'A_'+str(i)\n",
    "    filenames[i] = filename_dict[list(filename_dict)[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d0915c9-de62-4faf-8282-46a3710df415",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merge all las files or stages\n",
    "filter_merge = {\"type\":\"filters.merge\",\n",
    "               \"tag\": \"merged\",\n",
    "               \"inputs\": tags}\n",
    "# write merged las to raster\n",
    "writers_gdal= {\"type\": \"writers.gdal\",\n",
    "               'output_type': 'count',\n",
    "              'resolution': '1.0',\n",
    "               'inputs':'merged',\n",
    "               'bounds': writers_bounds,\n",
    "              'radius': '0.7',\n",
    "              'filename': output_tif}\n",
    "# Append each stage to a list prior to saving to json \n",
    "# pipeline_list = input_list[0]\n",
    "pipeline_list = filenames.copy()\n",
    "pipeline_list.append(filter_merge)\n",
    "pipeline_list.append(writers_gdal)\n",
    "# pipeline_list = [input_list[0], filter_range, writers_gdal]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "# save to json\n",
    "with open(count_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928d7047-0cda-4418-bb26-7d7e43902c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bfdb5c1-964d-435c-9449-9809c6734f98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_json = json_base_path+'count_from_las2.json' # define path to json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee74113b-e669-4010-9828-fa3b3d9846c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'MRB/Merced_lidar/NCALM/NCALM_MRB_20180921/HAG/'\n",
    "output_tif = 'MRB/Merced_lidar/NCALM/NCALM_MRB_20180921/counts/NCALM_MRB_20180921_counts.tif'\n",
    "onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "input_list = [input_path + s for s in onlyfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d3d7e49-206b-4d0f-bede-4de8d3c5a4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "558d3abd-9312-4500-bdde-fe7aade1fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_dict = {}\n",
    "tags = ['']*len(input_list)\n",
    "filenames = ['']*len(input_list)\n",
    "for i in range(len(input_list)):\n",
    "    filename_dict['filename_'+str(i)] = {'filename':input_list[i], 'tag':'A_'+str(i)}\n",
    "    tags[i] = 'A_'+str(i)\n",
    "    filenames[i] = filename_dict[list(filename_dict)[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccbb23ac-e0a2-4f72-ad54-5a7ab67f2910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merge all las files or stages\n",
    "filter_merge = {\"type\":\"filters.merge\",\n",
    "               \"tag\": \"merged\",\n",
    "               \"inputs\": tags}\n",
    "filter_range = {\"type\":\"filters.range\",\n",
    "                \"limits\": \"Z[:100]\",\n",
    "               \"tag\": \"ranged\",\n",
    "               \"inputs\": 'merged'}\n",
    "# write merged las to raster\n",
    "writers_gdal= {\"type\": \"writers.gdal\",\n",
    "               'output_type': 'count',\n",
    "              'resolution': '1.0',\n",
    "               'bounds': writers_bounds,\n",
    "              'radius': '0.7',\n",
    "              'filename': output_tif}\n",
    "# Append each stage to a list prior to saving to json \n",
    "# pipeline_list = input_list[0]\n",
    "pipeline_list = filenames.copy()\n",
    "pipeline_list.append(filter_merge)\n",
    "pipeline_list.append(filter_range)\n",
    "pipeline_list.append(writers_gdal)\n",
    "# pipeline_list = [input_list[0], filter_range, writers_gdal]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "# save to json\n",
    "with open(count_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "374d1e3f-2e5c-4e80-a3b5-ca34f4bd5adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b94406-b34a-4765-ab30-40c00eb77cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdal_cmd = ['pdal','pipeline', count_json]\n",
    "subprocess.run(pdal_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be9deb-3b19-4bee-926f-3b11c423ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2a024-05ce-41b2-aba4-f643cf399686",
   "metadata": {},
   "outputs": [],
   "source": [
    "(toc-tic)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33420c03-f570-4bf2-8ba6-bee9db01e6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
