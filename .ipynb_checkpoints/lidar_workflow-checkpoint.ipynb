{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "797f557e-435f-49cd-8002-2135758b8c67",
   "metadata": {},
   "source": [
    "# Lidar Processing Workflow\n",
    "**Cara Piske, Graduate Program of Hydrologic Sciences, 2022; Advisor: Dr. Adrian Harpold**<br>\n",
    "This code processes raw lidar point clouds in order to calculate snow depth using PDAL. <br>\n",
    "Lidar data were provided by the Airborne Snow Observatory (ASO), the National Center for Airborne Laser Mapping (NCALM), and Watershed Sciences Inc. (WSI). <br>\n",
    "\n",
    "The goal of this project is to process snow depth to the one-meter spatial scale while maintaining conservative under-canopy estimates. Therefore, little interpolation occurs under-canopy. We follow these protocols in order to obtain a 1-m rasterized product (as opposed to the 3-m rasterized product provided by ASO on the NSIDC data portal). NCALM and WSI flights were obtained through OpenTopography."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e7346b-ed91-48fe-912a-4dc9d7b20be4",
   "metadata": {},
   "source": [
    "Start by importing necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef19ecac-1150-469a-9a3f-3eb6f8b1c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary files\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import json # where we will save the json files to run a pipeline\n",
    "import os # for file management\n",
    "import subprocess # allows us to run command line commands\n",
    "import pdal # lidar processing package\n",
    "import rasterio\n",
    "import pyproj\n",
    "from osgeo import gdal\n",
    "\n",
    "import time\n",
    "# packages to copy files\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import glob\n",
    "# packages to extract wkt from polygon\n",
    "import shapefile\n",
    "import pygeoif\n",
    "# for parallel processing\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "# See lidar_functions.py\n",
    "import lidar_functions\n",
    "pdal_pipeline = 'C:\\\\Users\\cpiske\\.conda\\envs\\lidar\\Lib\\site-packages\\pdal\\pipeline.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afec494a-5f52-4fc5-8ced-a5886f938892",
   "metadata": {},
   "source": [
    "Note that many functions are dependent on specific directory structures. See README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd00aac-03ba-4d6d-a022-bbfad350854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set current working directory\n",
    "# path = 'path/to/current/working/directory/'\n",
    "# os.chdir(path)\n",
    "# os.getcwd() # print to ensure we're in the right directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11eb2762-4c68-4a8e-a2e0-3c4434606bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_base_path = 'piske_processing/PDAL_workflow/JSON/' # set so that we can redefine json across operating systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1933dbf5-603d-4eac-a4df-8ec90e6278d4",
   "metadata": {},
   "source": [
    "Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a6c326-633d-4550-b011-0f012e2b2825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set current working directory\n",
    "path = '/'\n",
    "os.chdir(path)\n",
    "os.getcwd() # print to ensure we're in the right directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87f30faa-fe09-4f19-b736-214b2aad11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_base_path = 'piske_processing/PDAL_workflow/JSON/' # set so that we can redefine json across operating systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8ca020-c0f4-40e5-92c0-f102dad6cb9e",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436eea6-1aef-403f-a7be-0d4195cbdd8f",
   "metadata": {},
   "source": [
    "## Info\n",
    "Get to know lidar file... <br>\n",
    "In general, running PDAL python bindings can be difficult, so an easy workaround is to initiate a terminal command and run via subprocess. This is what we'll do for most of the processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fce8d2-28ae-466b-a779-d3640b9cb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define input file\n",
    "# input_lid = 'full/path/to/las/lidar.las'\n",
    "# pdal_info_cmd = ['pdal','info',input_lid] # general info\n",
    "# pdal_metadata_cmd = ['pdal','info',input_lid,'--metadata'] # full file metadata, including details crs\n",
    "# subprocess.run(pdal_metadata_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ee9d55-d48f-4228-a49d-76b7f83e8370",
   "metadata": {},
   "source": [
    "Save results to a dictionary <br>\n",
    "This will be useful below when renaming files based on specific metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce21a8-7035-4261-a81e-83b58a9e26cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdal_info_results = subprocess.run(pdal_metadata_cmd, stdout = subprocess.PIPE) # stout (standard out), PIPE indicates that a new pipe to the child should be created\n",
    "# pdal_info_dict = json.loads(pdal_info_results.stdout.decode()) # create dict with metadata info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaa2852-9e99-4e2f-ab6e-d1ee311ec38c",
   "metadata": {},
   "source": [
    "## Retile\n",
    "Retiling lidar files can help with memory issues and allow for parallelization, speeding up processing. Standard tiles come in 500-1500m side lengths. Choose depending on point density and spatial extent of files. Many NCALM files come in 1000x1000m already. Buffer zones are dependent on point density etc. and allow for redundant classifications to avoid the edge effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f53392-26c0-4904-88e2-5f1a1749e6c5",
   "metadata": {},
   "source": [
    "**Single Folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84755a16-6c56-4a92-839f-5f6d09e1bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retile_input_path = 'path/to/input/lidar/folder/*.la*' # use * wildcard to identify all files that end in las or laz\n",
    "# retile_output_path = 'path/to/output/lidar/folder/#.laz' # # will be replaced by a number\n",
    "# onlyfiles = [f for f in os.listdir(retile_input_path) if os.path.isfile(os.path.join(retile_input_path, f))]\n",
    "# for files in onlyfiles:\n",
    "#     full_path = os.path.join(retile_input_path, files)\n",
    "#     output_path = retile_output_path+'retile_#'+files[-4:]\n",
    "#     retile_command = ['pdal', 'tile', full_path, output_path, '--length=1000','--buffer=50']\n",
    "#     subprocess.run(retile_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d68b9c-d164-4bd3-8f76-c7a835076eb8",
   "metadata": {},
   "source": [
    "**Multiple subdirectories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7737a-51ce-4717-a716-6f2bd64a6db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_folders = [x[0] for x in os.walk('folder1/folder2/SCB/')]\n",
    "# # list indices of all folders that are called laz or las (i.e. 'folder1/folder2/SCB/flight1/laz/')\n",
    "# index_pos_list = [ i for i in range(len(all_folders)) if (all_folders[i][-3:] == 'laz' or all_folders[i][-3:] == 'las') ]\n",
    "# # create list of all folder paths that end with directory named 'laz' or 'las'\n",
    "# lid_list = [all_folders[i] for i in index_pos_list]\n",
    "\n",
    "# # for each of these folders...\n",
    "# for lid_folders in lid_list:\n",
    "#     # input wildcard string (ex. 'folder1/folder2/SCB/flight1/laz/*.laz')\n",
    "#     input_file_wildcard = lid_folders + '/*.'+ lid_folders[-3:] # [-3:] allows us to use .las or .laz\n",
    "#     # output pathname w/ wildcard (ex. 'folder1/folder2/SCB/flight1/retile/retile_#.laz')\n",
    "#     output_path = lid_folders[:-3] + '/retile/retile_#.' + lid_folders[-3:]\n",
    "#     # create pdal command\n",
    "#     retile_cmd = ['pdal', 'tile', input_file_wildcard, output_path,'--length=1000','--buffer=50']\n",
    "#     subprocess.run(retile_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d29947-d28b-4f15-a15f-ba45ace15a23",
   "metadata": {},
   "source": [
    "## Rename\n",
    "Many files come with inconsistent naming (including unsupported characters...) <br>\n",
    "Rename all files to maintain consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a08ac24-eb5f-4486-8da8-0c4f47e6ce95",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # See lidar_functions.py\n",
    "# # This is function .py file \n",
    "# # rename a file with the lower left x and y defined as the corner point of the bounding box (add resolution/2 to get the center point of the box) \n",
    "# # input - full lidar file path (i.e. 'lidar_files/filename.laz'), str\n",
    "# # \n",
    "# def rename_llx_lly_b(full_path):\n",
    "    \n",
    "#     pdal_info_command = ['pdal', 'info', full_path, '--metadata'] # set up pdal info command\n",
    "#     pdal_info_results = subprocess.run(pdal_info_command, stdout = subprocess.PIPE) # stout (standard out), PIPE indicates that a new pipe to the child should be created, execute command\n",
    "#     pdal_info_dict = json.loads(pdal_info_results.stdout.decode()) # save metadata to dictionary\n",
    "#     pathname = os.path.dirname(os.path.realpath(full_path)) # isolate only pathname (i.e. 'folder1/folder2/SCB/flight1/lid_files/')\n",
    "#     new_name = os.path.join(pathname, str(round(pdal_info_dict['metadata']['minx'])) +\"_\"+ str(round(pdal_info_dict['metadata']['miny']))+full_path[-4:])    \n",
    "#     if os.path.exists(new_name):\n",
    "#         lidar_folder = pathname\n",
    "#         onlyfiles = [f for f in os.listdir(lidar_folder) if os.path.isfile(os.path.join(lidar_folder, f))]\n",
    "#         full_paths = [os.path.join(lidar_folder, s) for s in onlyfiles] \n",
    "#         full_str = ','.join(full_paths)\n",
    "#         num_occurences = full_str.count(new_name[:-4])\n",
    "#         new_name_b = new_name[:-4]+'_'+str(num_occurences)+new_name[-4:]\n",
    "#         os.rename(full_path, new_name_b)\n",
    "#     else:\n",
    "#         os.rename(full_path, new_name) # rename file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761a2f81-6bcf-4388-ad5f-de698c216f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # See lidar_functions.py\n",
    "# # rename a file with additional metadata at the beginning of the filename\n",
    "# # flight organization, watershed, date of flight (i.e. ASO_ICB_20140423)\n",
    "# # additional text will be taken from the flight directory name, could hardcode additional string instead of using folder name\n",
    "# # input - full lidar file path (i.e. 'lidar/lidar_files/filename.laz'), str\n",
    "\n",
    "# def add_str_to_filename2(full_path):\n",
    "#     filename = os.path.basename(full_path) # isolate only filename (i.e 'filename.laz')\n",
    "#     pathname = os.path.dirname(os.path.realpath(full_path)) # isolate only path name (i.e. 'lidar/lidar_files')\n",
    "#     add_str = os.path.normpath(pathname) # split up the path name (i.e. full path)\n",
    "#     add_str = [i for i in add_str.split(os.sep) if (i.startswith('ASO_') or i.startswith('NCALM_') or i.startswith('WSI_'))] # (i.e. 'ASO_SCB_2016')\n",
    "#     rename = os.path.join(pathname, add_str[0] + '_'+ filename) # add string to full pathname \n",
    "#     os.rename(full_path, rename) # rename file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f22c8c-db32-4cb5-ba75-593e3004bdb7",
   "metadata": {},
   "source": [
    "**Single file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a6166-4d4d-4841-be9b-e7b1bb5715eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename_llx_lly('filepath.laz')\n",
    "# add_str_to_filename2('new_filepath.laz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5860ebb2-f160-4bfa-be1b-599e357c41ca",
   "metadata": {},
   "source": [
    "**Multiple Folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d3df06-9d47-421c-b863-4e9b5f8bef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_folders = [x[0] for x in os.walk('path/to/folder/')]\n",
    "# for folders in all_folders:\n",
    "#     # list indices of all folders that are called laz\n",
    "#     index_pos_list = [ i for i in range(len(all_folders)) if all_folders[i][-6:] == 'retile' ]\n",
    "#     # save only those files \n",
    "#     retile_list = [all_folders[i] for i in index_pos_list]\n",
    "#     for lidar_folder in retile_list:\n",
    "#         rename_retiles(lidar_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cff4837-64c2-4eac-bb08-50ab9339c178",
   "metadata": {},
   "source": [
    "**Parallel Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eebb5f0-d0fd-4619-a7b0-d12fc37ec4f4",
   "metadata": {},
   "source": [
    "Single Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e4cc2f-6a00-4fde-9a32-c4b5e3605ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lidar_folder = 'path/to/lid/folder/'\n",
    "# tic = time.perf_counter()\n",
    "# if __name__ == '__main__':\n",
    "#     with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "#         onlyfiles = [f for f in os.listdir(lidar_folder) if os.path.isfile(os.path.join(lidar_folder, f))]\n",
    "#         full_path = [os.path.join(lidar_folder, s) for s in onlyfiles]\n",
    "#         executor.map(lidar_functions.rename_llx_lly, full_path) #running 10 times\n",
    "# toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc5fd4-3cb3-4304-acd3-fb2d3462c854",
   "metadata": {},
   "source": [
    "*Repeat with lidar_functions.add_str_to_filename...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32942d-f717-4927-b44a-53e966ae1cf2",
   "metadata": {},
   "source": [
    "use if there are - in the output filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff3226e-cbc3-4afe-9dd7-574b297c6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use if there are - in the output filename\n",
    "# pathname = 'Piske_lidar/MRB/Merced_lidar/ASO/ASO_MRB_20210429/tindex/tiles/'\n",
    "# for files in [f for f in os.listdir(pathname) if os.path.isfile(os.path.join(pathname, f))]:\n",
    "#     target = files.replace(\"-\",\"\")\n",
    "#     target = pathname + target\n",
    "#     full_path = pathname+files\n",
    "#     os.rename(full_path,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4192a006-96c8-4f98-be10-3c3c7b3b5200",
   "metadata": {},
   "source": [
    "## Save tile boundaries\n",
    "Save sqlite (shp) of tile boundaries of retiles <br>\n",
    "Alter filepaths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8700fa7-5eb7-4315-ae71-8a8f8e1e7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # see lidar_functions.py\n",
    "# # save the tile index of a file to a new folder\n",
    "\n",
    "# # input - full lidar/sqlite file patsh (i.e. 'lidar/lidar_files/filename.laz'), [str, str]\n",
    "# def create_tindex2(input_path, output_path):\n",
    "#     boundary_cmd = ['pdal', 'tindex', 'create', '--tindex', output_path, '--filespec', input_path, '-f', 'SQLite']\n",
    "#     subprocess.run(boundary_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae36ff13-c4ea-4b39-93d6-437501ca1a43",
   "metadata": {},
   "source": [
    "**Parallel Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19aa7a7-14ab-4d0e-b87c-f19d48306c3e",
   "metadata": {},
   "source": [
    "Single folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5ae699-3088-4040-8387-5a9c5a4c6537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # one folder\n",
    "# tic = time.perf_counter()\n",
    "# lidar_folder = 'path/to/lidar/files/'\n",
    "# if __name__ == '__main__':\n",
    "#     with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "#         onlyfiles = [f for f in os.listdir(lidar_folder) if os.path.isfile(os.path.join(lidar_folder, f))]\n",
    "#         full_path = [os.path.join(lidar_folder, s) for s in onlyfiles]\n",
    "#         # change depending on directory formats\n",
    "#         output_path = [os.path.join(os.path.basename(lidar_folder),'tindex' + s[:-3] + 'sqlite') for s in onlyfiles]\n",
    "#         executor.map(create_tindex, full_path, output_path) #running 10 times\n",
    "# toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa21d4af-54ce-4589-a4d9-02fc1c8bb3ff",
   "metadata": {},
   "source": [
    "all folders called \"retile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84409860-6b38-4487-bbc8-e679a9c2d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rename all retiled files\n",
    "# tic = time.perf_counter()\n",
    "# all_folders = [x[0] for x in os.walk('path/to/folder/')]\n",
    "# # list indices of all folders that are called laz\n",
    "# index_pos_list = [ i for i in range(len(all_folders)) if all_folders[i][-6:] == 'retile' ]\n",
    "# # save only those files \n",
    "# retile_list = [all_folders[i] for i in index_pos_list]\n",
    "# for lidar_folder in retile_list:\n",
    "#     if __name__ == '__main__':\n",
    "#         with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "#             onlyfiles = [f for f in os.listdir(lidar_folder) if os.path.isfile(os.path.join(lidar_folder, f))]\n",
    "#             full_path = [lidar_folder + '/' + s for s in onlyfiles]\n",
    "#             output_path = [lidar_folder[:-6] + 'tindex/' + s[:-3] + 'sqlite' for s in onlyfiles]\n",
    "#             executor.map(create_tindex, full_path, output_path) #running 10 times\n",
    "# toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e21b76-fc61-4c45-9bc7-f1280a3ae067",
   "metadata": {},
   "source": [
    "All files in ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ee447e-92c9-48bd-b5c5-6ff084891ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tic = time.perf_counter()\n",
    "# # list all folders in directory\n",
    "# all_folders = [x[0] for x in os.walk('Piske_lidar/MRB/Merced_lidar/NCALM/')]\n",
    "# # list indices of all folders that are called laz\n",
    "# index_pos_list = [ i for i in range(len(all_folders)) if all_folders[i][-3:] == 'laz' ]\n",
    "# # save only those files \n",
    "# laz_list = [all_folders[i] for i in index_pos_list]\n",
    "# for folders in laz_list:\n",
    "#     pathname = folders + '/'\n",
    "#     output_pathname = folders[:-3] + 'sqlite' + '/'\n",
    "#     onlyfiles = [f for f in os.listdir(pathname) if os.path.isfile(os.path.join(pathname, f))]\n",
    "#     for file in onlyfiles:\n",
    "#         input_las = pathname + file\n",
    "#         output_sqlite = output_pathname + file[:-4] + '.sqlite'\n",
    "#         boundary_cmd = ['pdal', 'tindex', 'create', '--tindex', output_sqlite, '--filespec', input_las, '-f', 'SQLite']\n",
    "#         subprocess.run(boundary_cmd)\n",
    "# toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a2070-2c2d-4f4d-acc7-2982914f2b81",
   "metadata": {},
   "source": [
    "## Copy files\n",
    "Save a copy of files that meet criteria into a new folder <br>\n",
    "The goal is to decrease processing time for datum conversions in the MRB <br>\n",
    "Change file extents depending on watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f073a7f7-f2cb-4bfc-a220-5261c4a03627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # see lidar_functions.py\n",
    "# # copy file based on llx and lly into output filename. Note that this function relies on the assumption that files follow the structure \n",
    "\n",
    "# # input_las 'folder1/folder2/folder3a/filename.laz' and output_las 'folder1/folder2/folder3b/filename.laz'\n",
    "# # if files are held in a different file structure, code must be changed to accomodate change\n",
    "# # input - full path to a las file\n",
    "# def copy_las_by_ext_ICB2(full_path):\n",
    "#     pdal_info_command = ['pdal', 'info', full_path, '--metadata'] # set up pdal command\n",
    "#     pdal_info_results = subprocess.run(pdal_info_command, stdout = subprocess.PIPE) # stout (standard out), PIPE indicates that a new pipe to the child should be created, execute command\n",
    "#     pdal_info_dict = json.loads(pdal_info_results.stdout.decode()) # save metadata to dict\n",
    "#     minx = round(pdal_info_dict['metadata']['minx'])\n",
    "#     miny = round(pdal_info_dict['metadata']['miny'])\n",
    "#     if (minx <= 288000 and minx >= 265000):\n",
    "#         if (miny >= 4165000 and miny<= 4180000):\n",
    "#             input_las = full_path\n",
    "#             output_las = os.path.join(os.path.dirname(os.path.realpath(os.path.dirname(os.path.realpath(full_path)))),'retile_ICB', os.path.basename(full_path))\n",
    "#             pdal_copy_cmd = ['pdal','translate', input_las, output_las]\n",
    "#             subprocess.run(pdal_copy_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00a1a8-28bd-4752-9f6b-6d97899287f3",
   "metadata": {},
   "source": [
    "**Parallel Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a7a6f8-70c5-43cc-bc6f-f7220b2bbffe",
   "metadata": {},
   "source": [
    "All folders called \"retile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f78ecbd-88af-42d9-9ad0-fa217cfb4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tic = time.perf_counter()\n",
    "# all_folders = [x[0] for x in os.walk('path/to/lidar/flight/')]\n",
    "# # list indices of all folders that are called laz\n",
    "# index_pos_list = [ i for i in range(len(all_folders)) if all_folders[i][-6:] == 'retile' ]\n",
    "# # save only those files \n",
    "# retile_list = [all_folders[i] for i in index_pos_list]\n",
    "# for lidar_folder in retile_list:\n",
    "#     if __name__ == '__main__':\n",
    "#         with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "#             onlyfiles = [f for f in os.listdir(lidar_folder) if os.path.isfile(os.path.join(lidar_folder, f))]\n",
    "#             full_path = [os.path.join(lidar_folder, s) for s in onlyfiles]\n",
    "#             executor.map(copy_las_by_ext_ICB, full_path) #running 10 times\n",
    "# toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6399d56f-bd50-4cfb-9368-1086a3d5bffa",
   "metadata": {},
   "source": [
    "### Copy tindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae4838f-0dd2-443a-94e6-3ae22f935115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_folders = [x[0] for x in os.walk('Piske_lidar/MRB/Merced_lidar/ASO')]\n",
    "# # list indices of all folders that are called laz\n",
    "# index_pos_list = [ i for i in range(len(all_folders)) if all_folders[i][-9:] == 'ICB_tiles' ]\n",
    "# # save only those files \n",
    "# ICB_retile_list = [all_folders[i] for i in index_pos_list]\n",
    "# for lidar_folder in ICB_retile_list:\n",
    "#     onlyfiles = [f for f in os.listdir(lidar_folder) if os.path.isfile(os.path.join(lidar_folder, f))]\n",
    "#     for files in onlyfiles:\n",
    "#         tindex_full_path = os.path.dirname(lidar_folder) + '/tindex/tiles/'+files[:-3]+'sqlite'\n",
    "#         if os.path.isfile(tindex_full_path):\n",
    "#             target_full_path = os.path.dirname(lidar_folder) + '/tindex/ICB_tiles/'\n",
    "#             shutil.copy2(tindex_full_path, target_full_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f29f9-902d-4112-b566-a0020a729d42",
   "metadata": {},
   "source": [
    "Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98684c-fa6b-4056-b1d0-880d5f538bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "lidar_folder = 'MRB/Merced_lidar/ASO/ASO_MRB_20210429/laz/'\n",
    "output_path = 'MRB/Merced_lidar/ASO/ASO_MRB_20210429/ICB_tiles/'\n",
    "onlyfiles = [f for f in os.listdir(lidar_folder) if os.path.isfile(os.path.join(lidar_folder, f))]\n",
    "full_paths = [os.path.join(lidar_folder, s) for s in onlyfiles] \n",
    "output_paths = np.repeat(output_path, len(full_paths))\n",
    "if __name__ == '__main__':\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        executor.map(lidar_functions.copy_lid_by_ext_ICB, full_paths, output_paths)\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc08c8f-e7f2-430a-b8d3-7649064e1287",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Datum Conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913244f4-51c7-4c8a-ae9c-9f1ed0ccdaab",
   "metadata": {},
   "source": [
    "### Horizontal Datum Conversion\n",
    "From PDAL library: https://pdal.io/tutorial/grid-shift.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b77dbfe-5199-4a43-9231-2b022fe93509",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_datum_conversion = json_base_path+'horizontal_datum_conversion.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb3d599-0898-4f70-9035-6a8d5bea7657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_las = 'path/to/filename/filename.las'\n",
    "# output_las = \"path/to/filename/filename.las\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820da99a-637f-438d-bb6d-cfbd5a8bde28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reader_dict = {\"type\":\"readers.las\",\n",
    "#               \"filename\":input_reproj_hor}\n",
    "\n",
    "# reproject_dict = {\"type\":\"filters.reprojection\",\n",
    "#                   \"in_srs\":\"+proj=utm +zone=10 +datum=WGS84 +units=m +no_defs\",\n",
    "#                   \"out_srs\":\"EPSG:26910\"} #\"in_srs\":\"EPSG:8999\"\n",
    "# writer_dict = {\"type\":\"writers.las\",\n",
    "#                \"a_srs\":\"EPSG:26910\",\n",
    "#               #  \"scale_x\":0.00000001,\n",
    "#               #  \"scale_y\":0.00000001,\n",
    "#               # \"offset_x\":\"auto\",\n",
    "#               # \"offset_y\":\"auto\",\n",
    "#               \"filename\":output_reproj_hor}\n",
    "\n",
    "# pipeline_list = [reader_dict, reproject_dict, writer_dict]\n",
    "# pipeline_dict = {'pipeline' : pipeline_list}\n",
    "# with open(horizontal_datum_conversion, 'w') as out:\n",
    "#     json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d367333-36ed-4375-be85-292e1cb5504c",
   "metadata": {},
   "source": [
    "### Vertical Datum Conversion\n",
    "using output of code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ed65b-202b-432b-a24f-d916ef6c8cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # best option for now \n",
    "# input_las = 'path/to/filename.las'\n",
    "# output_las = 'path/to/filename.las'\n",
    "# gtx_path = 'path/to/fielname.gtx' # /cpiske/lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/reproject/gtx_links/core/geoid12b/g2012bu5.gtx\n",
    "# reproj_fil_in_srs = '--filters.reprojection.in_srs=EPSG:26910+5703'\n",
    "# reproj_fil_out_srs = '--filters.reprojection.out_srs=+init=EPSG:26910' + ' +geoidgrids='+gtx_path + ' +t_epoch=2010.0'\n",
    "# writers_compression = '--writers.las.compression=true'\n",
    "# writers_a_srs = '--writers.las.a_srs=+proj=utm +zone=10 +ellps=GRS80 +datum=NAD83 +units=m +no_defs' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597edf1-6d46-4850-ac9c-fe5d127ccaa9",
   "metadata": {},
   "source": [
    "# Rasterize\n",
    "Set up the rasterization pipeline which we will use throughout the workflow. <br>\n",
    "We use two pipelines here, one which takes the mean of all points in a 1m pixel, using a 0.7m radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7e4d8-b390-460f-b479-23c7a453b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name JSON file\n",
    "rasterize_json_mean = json_base_path+'rasterize_mean.json'\n",
    "rasterize_json_count = json_base_path+'rasterize_count.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299fe1e3-959c-44aa-a2d9-e5eb9efb5c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline and save to a json file \n",
    "reader_dict = {'type':'readers.las'}\n",
    "writers_gdal= {\"type\": \"writers.gdal\",\n",
    "              'output_type': 'mean',\n",
    "              'resolution': '1.0',\n",
    "              'radius': '0.7'}#,\n",
    "             #'window_size':3,\n",
    "              #'default_srs':'EPSG:26910'}\n",
    "\n",
    "pipeline_list = [reader_dict,writers_gdal]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(rasterize_json_mean, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd96eb00-56a3-4761-b030-1f60ff06c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline and save to a json file \n",
    "reader_dict = {'type':'readers.las'}\n",
    "writers_gdal= {\"type\": \"writers.gdal\",\n",
    "              'output_type': 'mean',\n",
    "              'resolution': '1.0',\n",
    "              'radius': '0.7'}#,\n",
    "             #'window_size':3,\n",
    "              #'default_srs':'EPSG:26910'}\n",
    "\n",
    "pipeline_list = [reader_dict,writers_gdal]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(rasterize_json_mean, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adeead3-aada-4acc-9f3a-9125d76bab43",
   "metadata": {},
   "source": [
    "**Single Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07c5e51-9641-4e7b-aacf-2826f3db4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Single Files\n",
    "# reader = '--readers.las.filename='+'path/to/file/filename.las'\n",
    "# writer = '--writers.gdal.filename='+'path/to/file/filename.tif'\n",
    "# rasterize_command = ['pdal', 'pipeline', rasterize_json_mean, writer, reader]\n",
    "# subprocess.run(rasterize_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515d31e-20fd-455d-9c57-ad2c3b5d4935",
   "metadata": {},
   "source": [
    "**parallel processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb31ce-5fc0-43c6-9135-d2ed202c6996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tic = time.perf_counter()\n",
    "# input_path = 'path/to/lid/'\n",
    "# output_path = 'path/to/tif/'\n",
    "# if __name__ == '__main__':\n",
    "#     with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "#         onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "#         full_input_las = [input_path + '/' + s for s in onlyfiles]\n",
    "#         full_output_tif = [output_path + '/' + s[:-4] + '.tif' for s in onlyfiles]\n",
    "#         executor.map(rasterize_count, full_input_las, full_output_tif) \n",
    "# toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f4533-c27f-43b4-b977-dda256804922",
   "metadata": {},
   "source": [
    "Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9605a-6bbd-4c22-9447-45ccc4b5c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time = 3.2 min\n",
    "tic = time.perf_counter()\n",
    "input_path = 'SCB/Sagehen_lidar/ASO/ASO_SCB_20160326/corrected_las/'\n",
    "output_path = 'SCB/Sagehen_lidar/ASO/ASO_SCB_20160326/corrected_tif/'\n",
    "if __name__ == '__main__':\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "        full_input_las = [input_path + s for s in onlyfiles]\n",
    "        full_output_tif = [output_path + s[:-4] + '.tif' for s in onlyfiles]\n",
    "        executor.map(lidar_functions.rasterize_mean, full_input_las, full_output_tif) \n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdddc28-9144-43a7-9f58-7682c9469c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "input_path = 'SCB/Sagehen_lidar/ASO/ASO_SCB_20160417/corrected_las/'\n",
    "output_path = 'SCB/Sagehen_lidar/ASO/ASO_SCB_20160417/corrected_tif/'\n",
    "if __name__ == '__main__':\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "        full_input_las = [input_path + s for s in onlyfiles]\n",
    "        full_output_tif = [output_path + s[:-4] + '.tif' for s in onlyfiles]\n",
    "        executor.map(lidar_functions.rasterize_mean, full_input_las, full_output_tif) \n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb47785-633e-481c-a605-4b4e577c066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "input_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/ground_filtered/'\n",
    "output_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/ground_filtered_tif/'\n",
    "if __name__ == '__main__':\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "        full_input_las = [input_path + s for s in onlyfiles]\n",
    "        full_output_tif = [output_path + s[:-4] + '.tif' for s in onlyfiles]\n",
    "        executor.map(lidar_functions.rasterize_mean, full_input_las, full_output_tif) \n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00241f-c4cc-41d7-82d0-4d92b5db3a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3608299f-146c-46d5-84bf-2e4d9425eb40",
   "metadata": {},
   "source": [
    "# Ground Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48327ac8-4416-405c-85b3-e4df221101d9",
   "metadata": {},
   "source": [
    "## Assign Ground\n",
    "Modified from [Chambers, Bradley (2017). Ground Filter Tutorial.](https://pdal.io/tutorial/ground-filters.html) <br>\n",
    "See [SMRF filter documentation](https://pdal.io/stages/filters.smrf.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b0bd05-cff5-4913-9f47-09ba51b355bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name JSON file\n",
    "assign_ground_json = json_base_path +'assign_ground.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c3714-9583-458e-9b08-f8fbe7b257c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a pipeline and save to a json file \n",
    "\n",
    "filter_dict_assign = {'type':'filters.assign', # set the value of a dimension for all points to a provided value that pass a range filter\n",
    "                      \"assignment\":\"Classification[:]=0\"} #  single option has been provided that specifies the dimension, range, and value to assign. In this case, we are stating that we would like to apply a value of 0 to the Classification dimension for every point\n",
    "\n",
    "filter_dict_elm = {'type':'filters.elm'} # identify low noise points that can adversely affect ground segmentation algorithms, automatically assigns value of 7 \n",
    "\n",
    "filter_dict_outlier = {'type':'filters.outlier'} #  two methods of outlier detection at the moment: radius and statistical. Both aim to identify points that are isolated and likely arise from noise sources, classify values as 7\n",
    "# classify ground points\n",
    "filter_dict_smrf = {\"type\":\"filters.smrf\",\n",
    "                    \"ignore\":\"Classification[7:7]\"}#, # ignore outliers\n",
    "                    #\"slope\":0.3,\n",
    "                    #\"window\":16,\n",
    "                    #\"threshold\":0.15,\n",
    "                    #\"scalar\":1.2}\n",
    "\n",
    "\n",
    "pipeline_list = [filter_dict_assign,filter_dict_elm, filter_dict_outlier, filter_dict_smrf]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(assign_ground_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a6e321-b041-4aca-b5ee-2241b40cbf57",
   "metadata": {},
   "source": [
    "**Single File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33c74d-d2ea-4494-aa21-59b5836da496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdal_commands = ['pdal', 'translate', 'input_las.las', \"output_las.las\", '--json', assign_ground_json]\n",
    "# subprocess.run(pdal_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af513ea7-acad-4940-8bd3-592f78a82eac",
   "metadata": {},
   "source": [
    "**All Files in Folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2597ce7b-6f16-4203-ab32-64140beb02a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathname = 'path/to/lidar/folder/'\n",
    "# output_pathname = \"path/to/output/lidar/folder/\"\n",
    "# onlyfiles = [f for f in os.listdir(pathname) if os.path.isfile(os.path.join(pathname, f))]\n",
    "# for file in onlyfiles:\n",
    "#     input_las = pathname + file\n",
    "#     output_las = output_pathname + file\n",
    "#     pdal_commands = ['pdal', 'translate', input_las, output_las, '--json', gf_json]\n",
    "#     subprocess.run(pdal_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d8d12-ab95-4eae-82ea-4c9cc49ad718",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filter by Ground\n",
    "Filter classified las files based on [Las 1.4 Specifications](http://www.asprs.org/wp-content/uploads/2019/03/LAS_1_4_r14.pdf)<br>\n",
    "Where Classification 2 = ground <br>\n",
    "Classification 7 = noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188f6d2-0f8d-4aab-90c4-e86f024ef402",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_json = json_base_path+'ground_filter_preClassified.json' # define path to json files\n",
    "\n",
    "filter_range = {\"type\":\"filters.range\", \n",
    "                \"limits\":\"Classification[2:2]\"}\n",
    "pipeline_list = [filter_range]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "# save to json\n",
    "with open(gf_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43df2ce-870c-4cda-8bae-99551a154645",
   "metadata": {},
   "source": [
    "**Single File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea2950-4175-4d41-976a-4cebe29a9709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_las = 'path/to/lid/file/filenam.las'\n",
    "# output_las = 'path/to/lid/file/filename.las'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a611e7d2-02f1-497c-b16a-bad4ad7c2e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range_cmd = ['pdal', 'translate', input_las,  output_las, '--json',gf_json]\n",
    "# subprocess.run(range_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df014e65-d9b4-4b11-ab60-d1d8cfb37818",
   "metadata": {},
   "source": [
    "**All Files in Directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da82915d-9afe-4011-a28c-c718d9385d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #329.1668573822826s\n",
    "# tic = time.perf_counter()\n",
    "# input_path = 'path/to/input/directory'\n",
    "# output_path = 'path/to/output/directory'\n",
    "# if __name__ == '__main__':\n",
    "#     with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "#         onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "#         full_path = [input_path + '/' + s for s in onlyfiles]\n",
    "#         output_path_full = [output_path + '/' + s for s in onlyfiles]\n",
    "#         executor.map(lidar_functions.ground_filter_preClassified, full_path, output_path_full) #running 10 times\n",
    "# toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63db602d-9fcc-434c-9ba0-bb1b8c1f106a",
   "metadata": {},
   "source": [
    "## Create DEM\n",
    "This pipeline combines aboves steps to avoid issues with merging rasters. We were seeing tile signatures when we merged all tif files after ground-filtering/rasterization, so here we combine these steps through merging the las and then rasterizing (importantly, we are not writing the merged las files to a new merged file, which defeatst the purpose of tiles). A weakness of this pipeline is that it doesn't allow for tile-level parallelization <br> see: https://pdal.io/pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6da2558-582a-4f89-b6d0-a38e2b1c707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEM_json = json_base_path+'DEM_from_las.json' # define path to json files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae9b4f2-b703-4abc-a640-d282c933be43",
   "metadata": {},
   "source": [
    "Define the las files we want to create a DEM from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de06f83c-ddda-4906-b2d3-68e81f9cac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/ground_filtered/'\n",
    "output_tif = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/testb.tif'\n",
    "onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))] # make a list of all filenames in directory\n",
    "input_list = [input_path + s for s in onlyfiles] # make a list of full filename paths in directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49074ab-8990-4c85-8daf-d074f144a23a",
   "metadata": {},
   "source": [
    "Create the reader stages of the pipeline. Each file is read as an individual reader stage here, and we cheat here by copying the formatting of json files and creating a dictionary with the values as the correctly formatted inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf4967-3b22-41e9-a61a-d548d791995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_dict = {} # initiate an empty dict to hold the readers\n",
    "tags = ['']*len(input_list) # initiate an empty list, size = number of files\n",
    "filenames = ['']*len(input_list) # repeat\n",
    "for i in range(len(input_list)): # for each file, create a dictionary element with the values matching json formatting for file merging\n",
    "    filename_dict['filename_'+str(i)] = {'filename':input_list[i], 'tag':'A_'+str(i)}\n",
    "    tags[i] = 'A_'+str(i) # add a tag to the reader stage\n",
    "    filenames[i] = filename_dict[list(filename_dict)[i]] # Add all values to a list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad52c80-eb6d-4b7f-bff7-98daa477a0e7",
   "metadata": {},
   "source": [
    "Define the filter and writer stages of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b18dffb-0523-440d-8e12-d13db245a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the ground points of the tiles\n",
    "filter_range = {\"type\":\"filters.range\",\n",
    "                \"limits\":\"Classification[2:2]\"}\n",
    "# merge all las files or stages\n",
    "filter_merge = {\"type\":\"filters.merge\",\n",
    "               \"tag\": \"merged\",\n",
    "               \"inputs\": tags}\n",
    "# write merged las to raster\n",
    "writers_gdal= {\"type\": \"writers.gdal\",\n",
    "               'output_type': 'mean',\n",
    "              'resolution': '1.0',\n",
    "              'radius': '0.7',\n",
    "               'window_size':3,\n",
    "               'filename': output_tif}\n",
    "# Append each stage to a list prior to saving to json \n",
    "pipeline_list = filenames.copy()\n",
    "pipeline_list.append(filter_merge)\n",
    "#pipeline_list.append(filter_range)\n",
    "pipeline_list.append(writers_gdal)\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "# save to json\n",
    "with open(DEM_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a2727-5d65-414a-b13a-52209a70d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdal_cmd = ['pdal','pipeline', DEM_json]\n",
    "subprocess.run(pdal_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceede00-eb91-4562-9cdc-fb2034abdc4f",
   "metadata": {},
   "source": [
    "# HAG and Noise Filter\n",
    "Height above ground DEM (raster format). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3146179f-5906-4f9e-a81e-a0f939b1cc35",
   "metadata": {},
   "source": [
    "## Replace Z with HAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab65f9a-5992-49ae-8593-a29fdd88646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define json path \n",
    "HAG_json = json_base_path + 'HAG_dem.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ca73ed-543d-4024-a9fe-8dfa8331795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all z values to the height above ground \n",
    "target_dem = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/DEM/NCALM_2014_BE.tif'\n",
    "filter_hag = {\"type\":\"filters.hag_dem\",\n",
    "              \"raster\":target_dem, # full file path of target DEM (.tif)\n",
    "              \"zero_ground\":\"false\"} # Do not assign 0 to ground classified points\n",
    "filter_ferry = {\"type\":\"filters.ferry\",\n",
    "                \"dimensions\":\"HeightAboveGround=>Z\"} # replace all Z dimensions with HAG instead of elevation\n",
    "filter_range = {\"type\":\"filters.range\",\n",
    "                \"limits\":\"Z[-0.2:70]\"} # apply a noise filter\n",
    "pipeline_list = [filter_hag, filter_ferry,filter_range]#,filter_range]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(HAG_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c59b90-ae2f-4f10-aea1-d998229902e6",
   "metadata": {},
   "source": [
    "**Single Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0950d373-9976-4959-89b2-823496a7b01c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input_las = \"path/to/full/filename/filename.laz\"\n",
    "# output_las = \"path/to/full/filename/filename.laz\"\n",
    "# HAG_cmd = ['pdal', 'translate',input_las, output_las, '--json', HAG_json]\n",
    "# subprocess.run(HAG_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff387277-2d63-48ea-99c6-c065c70a076c",
   "metadata": {},
   "source": [
    "**Multiple Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e915847b-3725-4eaa-9e54-31eafcbd0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # multiple files\n",
    "# pathname = \"path/to/lid/folder/\"\n",
    "# output_pathname = \"path/to/lid/folder/\"\n",
    "# onlyfiles = [f for f in os.listdir(pathname) if os.path.isfile(os.path.join(pathname, f))]\n",
    "# for file in onlyfiles:\n",
    "#     input_las = pathname + file\n",
    "#     output_las = output_pathname + file\n",
    "#     HAG_cmd = ['pdal', 'translate',input_las, output_las, '--json', HAG_json]\n",
    "#     subprocess.run(HAG_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab32ad77-3a2c-4777-9bf0-f88da02214fb",
   "metadata": {},
   "source": [
    "**Parallel Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c68e1-b2ef-4e2d-b9bd-3c82f3f444a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tic = time.perf_counter()\n",
    "# input_path = 'path/to/lid/folder/'\n",
    "# output_path = 'path/to/lid/folder/'\n",
    "# if __name__ == '__main__':\n",
    "#     with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "#         onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "#         full_path = [input_path + s for s in onlyfiles]\n",
    "#         output_path_full = [output_path + s for s in onlyfiles]\n",
    "#         executor.map(lidar_functions.HAG_dem, full_path, output_path_full) #running 10 times\n",
    "# toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af170f51-b699-4729-955a-59b8f6cc3fbc",
   "metadata": {},
   "source": [
    "Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f273dd2d-0b66-46f0-a99b-b9bf92de343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel processing\n",
    "# time = 1.1 min\n",
    "tic = time.perf_counter()\n",
    "input_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/NAD83_NAD83_epoch2010/'\n",
    "output_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/HAG/'\n",
    "if __name__ == '__main__':\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "        full_path = [input_path + s for s in onlyfiles]\n",
    "        output_path_full = [output_path  + s for s in onlyfiles]\n",
    "        executor.map(lidar_functions.HAG_dem, full_path, output_path_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401000f9-2bc3-4aa1-ac26-871ff12e4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(toc-tic)/60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4252154-a780-4aba-8f9a-3fefccf8edf2",
   "metadata": {},
   "source": [
    "## Add a new dimension\n",
    "Add a new dimension to the file but maintain Z values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bdee97-69bd-4634-86f6-368120456623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this works to add a new dimension\n",
    "# output_las_hag = 'input/lid/files/lidar.laz'\n",
    "# filter_dem = '--filters.hag_dem.raster=' + target_DEM\n",
    "# hag_addDim = ['pdal', 'translate', input_las_hag, output_las_hag, 'hag_dem' ,filter_dem, '--writers.las.extra_dims=HeightAboveGround=float32']\n",
    "# subprocess.run(hag_addDim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96d8471-c3d2-4d8c-8399-80123ec762f3",
   "metadata": {},
   "source": [
    "# Vertical Bias Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9c65aa-b334-4894-8d1d-1897eb04b52c",
   "metadata": {},
   "source": [
    "## Move files\n",
    "Make a copy of road covered tiles. <br>\n",
    "The spatial extents of the road polygon are 738382,4371452 : 738686,4372063 <br>\n",
    "chose only files with a min x > 737000 and a min y > 4370000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed5feb-c166-4a78-9b2a-1c9e8a8446d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # defining source and destination\n",
    "# # paths\n",
    "# src = 'path/to/source/folder/*.la*'\n",
    "# trg = 'path/to/target/folder/target'\n",
    "# file_paths = glob.glob(src)\n",
    "\n",
    "# for files in file_paths:\n",
    "#     filename = os.path.basename(files)\n",
    "#     if int(files[-18:-12]) > 737000 and int(files[-11:-4]) > 4370000:\n",
    "#     # copying the files to the\n",
    "#     # destination directory\n",
    "#         shutil.copy2(files, trg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3bea70-a8ec-4502-8b82-1f1e61cb7e9a",
   "metadata": {},
   "source": [
    "Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5818571-a968-43f1-9514-6ef591da593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining source and destination\n",
    "# paths\n",
    "src = 'SCB/Sagehen_lidar/ASO/ASO_SCB_20160417/HAG/*.la*'\n",
    "trg = 'SCB/Sagehen_lidar/ASO/ASO_SCB_20160417/hwy89_vertical_bias/target_lid'\n",
    "file_paths = glob.glob(src)\n",
    "\n",
    "for files in file_paths:\n",
    "    filename = os.path.basename(files)\n",
    "    if int(files[-18:-12]) > 737000 and int(files[-11:-4]) > 4370000:\n",
    "    # copying the files to the\n",
    "    # destination directory\n",
    "        shutil.copy2(files, trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e6e743-7858-49c8-ac0f-6975603ee308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining source and destination\n",
    "# paths\n",
    "src = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_20080210/HAG/*.la*'\n",
    "trg = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_20080210/hwy89_vertical_bias/target_lid'\n",
    "file_paths = glob.glob(src)\n",
    "\n",
    "for files in file_paths:\n",
    "    filename = os.path.basename(files)\n",
    "    if int(files[-18:-12]) > 737000 and int(files[-11:-4]) > 4370000:\n",
    "    # copying the files to the\n",
    "    # destination directory\n",
    "        shutil.copy2(files, trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39152a7f-67cd-4480-99f0-c09abd160d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(os.path.basename(file_paths[0])[-11:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d7eee-ca20-4316-8770-9caf004b2983",
   "metadata": {},
   "source": [
    "## Merge\n",
    "Merge files over the road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddac58e-07e1-48b2-910e-1771140fd18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_path = 'path/to/target_lid/*.la*' # define path of input files\n",
    "# output_fname = 'path/to/target/filename.laz'# set output filename\n",
    "# input_fname = glob.glob(input_path) # save to list\n",
    "# pdal_merge_command = input_fname\n",
    "# pdal_merge_command.insert(len(pdal_merge_command),output_fname) # insert output file to list\n",
    "# #pdal_merge_command.insert(0,'-f')\n",
    "# pdal_merge_command.insert(0,'merge')\n",
    "# pdal_merge_command.insert(0,'pdal')\n",
    "# subprocess.run(pdal_merge_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b52109-338b-429e-8f4a-7ac658f497b8",
   "metadata": {},
   "source": [
    "Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848cda3-c0e6-4a8b-8f03-860c8fad571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'SCB/Sagehen_lidar/ASO/ASO_SCB_20160417/hwy89_vertical_bias/target_lid/*.la*' # define path of input files\n",
    "input_fname = glob.glob(input_path) # save to list\n",
    "output_fname = 'SCB/Sagehen_lidar/ASO/ASO_SCB_20160417/hwy89_vertical_bias/target_lid/ASO_SCB_20160417_hwy89_merge.'+input_fname[0][-3:]# set output filename\n",
    "pdal_merge_command = input_fname\n",
    "pdal_merge_command.insert(len(pdal_merge_command),output_fname) # insert output file to list\n",
    "#pdal_merge_command.insert(0,'-f')\n",
    "pdal_merge_command.insert(0,'merge')\n",
    "pdal_merge_command.insert(0,'pdal')\n",
    "subprocess.run(pdal_merge_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99227d65-ea58-4256-ae32-a7e08f7067e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/hwy89_vertical_bias/target_lid/*.la*' # define path of input files\n",
    "input_fname = glob.glob(input_path) # save to list\n",
    "output_fname = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/hwy89_vertical_bias/target_lid/NCALM_SCB_2014_hwy89_merge.'+input_fname[0][-3:]# set output filename\n",
    "pdal_merge_command = input_fname\n",
    "pdal_merge_command.insert(len(pdal_merge_command),output_fname) # insert output file to list\n",
    "#pdal_merge_command.insert(0,'-f')\n",
    "pdal_merge_command.insert(0,'merge')\n",
    "pdal_merge_command.insert(0,'pdal')\n",
    "subprocess.run(pdal_merge_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9bd53f-151f-4372-a350-b0508ebdd129",
   "metadata": {},
   "source": [
    "## Clip\n",
    "Crop file to outline of the road shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dff30f-58d1-4fde-a8f7-fbc43e6d52c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name JSON file\n",
    "clip_json = json_base_path +'clip_to_geometries.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ea3b1-6f9b-48a4-8d72-f8aa1c920f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_shapefile = 'SCB/supporting_files/bounding_box/hwy89_poly.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa11d72-f70c-41b5-9fde-1e6b9d78ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract wkt from hwy 89 polygon\n",
    "hwy89 = shapefile.Reader(path_to_shapefile)\n",
    "geom=[]\n",
    "for s in hwy89.shapes():\n",
    "    geom.append(pygeoif.geometry.as_shape(s)) \n",
    "poly_base = pygeoif.MultiPolygon(geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c812914-fe1f-4e42-ac6b-9d536fcb52c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline and save to a json file \n",
    "filter_crop = {'type':'filters.crop',\n",
    "                 'polygon':poly_base.wkt}\n",
    "pipeline_list = [filter_crop]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(clip_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debc6066-e045-4733-893a-77aef7147dc5",
   "metadata": {},
   "source": [
    "**Single Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d297c8c-9339-4935-8866-79cc0179f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdal_commands = ['pdal', 'translate', input_las, output_las, '--json', clip_json]\n",
    "# subprocess.run(pdal_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867a932-fdf4-4815-9918-d4e92c511dfc",
   "metadata": {},
   "source": [
    "Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71402413-e728-42b6-91cb-a000371da216",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_las = '/SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/hwy89_vertical_bias/target_lid/NCALM_SCB_2014_hwy89_merge.las'\n",
    "output_las = '/SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/hwy89_vertical_bias/clipped/NCALM_SCB_2014_hwy89_clip.las'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d09b842-a504-4bab-8c81-8af8d202f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdal_commands = ['pdal', 'translate', input_las, output_las, '--json', clip_json]\n",
    "subprocess.run(pdal_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624558b-84f7-41c6-90ad-420c4354ec39",
   "metadata": {},
   "source": [
    "## Calculate Stats Over Control Area\n",
    "In Kostadinov et al., 2019 the vertical bias was corrected using the lowest 10th percentile value between the snow on and snow off flights above the road. We will calculate a number of statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff93bcd6-1f96-4a80-8d7a-ba68c5f79c54",
   "metadata": {},
   "source": [
    "### Calculate Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe977b-b130-447f-a776-6a97a1aa9836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_las - HAG, las file clipped to the road\n",
    "# output_path - path to output files\n",
    "# base_name - string, typically flight name\n",
    "def calculate_vertical_bias(input_las):\n",
    "    # convert height only to txt file\n",
    "    output_las_txt = input_las[:-3]+'csv'\n",
    "    txt_cmd = ['pdal', 'translate', input_las, output_las_txt, '-w', 'writers.text', '--writers.text.format=csv','--writers.text.order=Z', '--writers.text.keep_unspecified=false']\n",
    "    subprocess.run(txt_cmd)\n",
    "    # calculate stats\n",
    "    hag_arr = np.loadtxt(output_las_txt,skiprows=1)\n",
    "    lowest_10th_per = np.nanpercentile(hag_arr, 10)\n",
    "    mean_hag = np.nanmean(hag_arr)\n",
    "    median_hag = np.nanmedian(hag_arr)\n",
    "    stats = [\"lowest_10th\",lowest_10th_per, \"mean\",mean_hag, \"median\", median_hag]\n",
    "    return(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4846a4-bbaa-444e-b3ed-5e32f99b97a7",
   "metadata": {},
   "source": [
    "Applied\n",
    "Using 2014 NCALM Flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0cd43-447f-40c8-9bd1-73711bfbe4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASO_20160326_hwy89_stats = calculate_vertical_bias('SCB/Sagehen_lidar/ASO/ASO_SCB_20160326/hwy89_vertical_bias/clipped/ASO_SCB_20160326_hwy89_clip.laz')\n",
    "ASO_20160417_hwy89_stats = calculate_vertical_bias('SCB/Sagehen_lidar/ASO/ASO_SCB_20160417/hwy89_vertical_bias/clipped/ASO_SCB_20160417_hwy89_clip.laz')\n",
    "ASO_20160518_hwy89_stats = calculate_vertical_bias('SCB/Sagehen_lidar/ASO/ASO_SCB_20160518/hwy89_vertical_bias/clipped/ASO_SCB_20160518_hwy89_clip.las')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724eab8-e366-4c29-a3d0-33d69b753df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCALM_2014_hwy89_stats = calculate_vertical_bias('SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/hwy89_vertical_bias/clipped/NCALM_SCB_2014_hwy89_clip.las')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670984d-73d8-462e-b036-31e6d3dd2015",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ASO_20160326_hwy89_stats)\n",
    "print(ASO_20160417_hwy89_stats)\n",
    "print(ASO_20160518_hwy89_stats)\n",
    "print(NCALM_2014_hwy89_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d4de4-992b-45d8-8595-85fa88beaa84",
   "metadata": {},
   "source": [
    "## Correct Z Values\n",
    "Using PDAL filters.assign we can add a value to each lidar point\n",
    "See lidar_functions.py - correct_by-target_val <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1828ebe0-561f-4d93-a709-e1299cf41897",
   "metadata": {},
   "source": [
    "### Correct LAS Only\n",
    "This involves simple command line function operations instead of a json derived pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50f9689-0fe8-4948-a617-a99e1e15bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_lid = 'path/to/input/filename/filename.laz'\n",
    "# output_lid = 'path/to/output/file/filename.laz'\n",
    "# filters_assign = '--filters.assign.value=Z=Z'+target_val\n",
    "# assign_cmd = ['pdal', 'translate', input_lid, output_lid, 'assign' ,filters_assign]\n",
    "# subprocess.run(assign_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23069994-84d1-4775-901d-d5de2df658e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # or use function\n",
    "# # assign target val\n",
    "# correct_by_targetVal_pipeline(target_val)\n",
    "# full_input_path = 'path/to/input/filename/filename.laz'\n",
    "# full_output_path = 'path/to/output/file/filename.laz'\n",
    "# target_val = 0\n",
    "# lidar_functions.correct_by_targetVal(full_input_path, full_output_path, target_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5863e1-f95b-42f5-8c5a-b23f924c3fc1",
   "metadata": {},
   "source": [
    "**Parallelize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b353a-ffdd-4e67-bd9a-a54e5574ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tic = time.perf_counter()\n",
    "# input_path = 'path/to/lid/folder/'\n",
    "# output_path = 'path/to/lid/folder/'\n",
    "# if __name__ == '__main__':\n",
    "#     with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "#         onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "#         full_path = [input_path + s for s in onlyfiles]\n",
    "#         output_path_full = [output_path + s for s in onlyfiles]\n",
    "#         target_vals = np.repeat(target_val, len(full_path))\n",
    "#         executor.map(lidar_functions.correct_by_targetVal, full_path, output_path_full, target_vals) \n",
    "# toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c950fb1-51e9-437a-8d3d-059af9b1b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "input_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/HAG/'\n",
    "output_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/corrected_las/'\n",
    "target_val = 'Z+'+str(abs(NCALM_2014_hwy89_stats[1])) # lowest 10th percentile \n",
    "if __name__ == '__main__':\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "        full_path = [input_path + s for s in onlyfiles]\n",
    "        output_path_full = [output_path + s for s in onlyfiles]\n",
    "        target_vals = np.repeat(target_val, len(full_path))\n",
    "        executor.map(lidar_functions.correct_by_targetVal, full_path, output_path_full, target_vals)\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af023f2f-1e3d-455e-a4c3-9f562731dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_functions.correct_by_targetVal(full_path[0], output_path_full[0], target_vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb12df9-d815-4e2c-88ee-fbcdb20c380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_functions.correct_by_targetVal(full_path[0], output_path_full[0], target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec00e0b9-a256-42f4-9089-58392a8d83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_assign = '--filters.assign.value=Z=Z+0.08'\n",
    "assign_cmd = ['pdal', 'translate', full_path[0], output_path_full[0], 'assign' ,filters_assign]\n",
    "subprocess.run(assign_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b13e5-3b84-454b-8ba7-e42bf62bac03",
   "metadata": {},
   "source": [
    "### Correct LAS and Rasterize\n",
    "For this section, we overwrite the json for each flight depending on the target value. This is beneficial for saving memory (no redundant corrected las files created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52dfa85-c720-4415-9614-59a111300465",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_rasterize_json = json_base_path + 'correct_by_targetVal_rasterize.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd4957a-4782-453d-8aea-8ac91e44b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that the corrected Z is Z - target val, because we are using the height above ground\n",
    "# input: target_assign - str e.g 'Z+0.08'\n",
    "def correct_by_targetVal_pipeline(target_assign):\n",
    "    readers_las = {'type':'readers.las'}\n",
    "    filters_assign = {'type': 'filters.assign',\n",
    "                      'value':\"Z=\"+target_assign}\n",
    "    writers_gdal= {\"type\": \"writers.gdal\",\n",
    "                  'output_type': 'mean',\n",
    "                  'resolution': '1.0',\n",
    "                  'radius': '0.7'}\n",
    "    pipeline_list = [readers_las,filters_assign,writers_gdal]\n",
    "    pipeline_dict = {'pipeline' : pipeline_list}\n",
    "    with open(correct_rasterize_json, 'w') as out:\n",
    "        json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52921924-7680-49af-afe2-98dcaeb453db",
   "metadata": {},
   "source": [
    "**Single Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61f447e-8a36-4ae0-b619-6af3a3c3a1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_input_path = 'path/to/input/lid/filename.las'\n",
    "# full_output_path = 'path/to/output/lid/filename.las'\n",
    "# target_val = -9999\n",
    "# correct_by_targetVal_pipeline(target_val)\n",
    "# lidar_functions.correct_by_targetVal_rasterize(full_input_path, full_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e620c8d-1922-48cc-80b1-5e04f24ee034",
   "metadata": {},
   "source": [
    "Applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84f9983-f55b-4bfa-84f0-481e3d134207",
   "metadata": {},
   "source": [
    "**Parallel Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18cc446-73fd-4dc9-a461-0cd82f76b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tic = time.perf_counter()\n",
    "# input_path = 'path/to/lid/folder/'\n",
    "# output_path = 'path/to/lid/folder/'\n",
    "# if __name__ == '__main__':\n",
    "#     with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "#         onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "#         full_path = [input_path + '/' + s for s in onlyfiles]\n",
    "#         output_path_full = [output_path + '/' + s for s in onlyfiles]\n",
    "#         executor.map(lidar_functions.correct_by_targetVal, full_path, output_path_full) #running 10 times\n",
    "# toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9c6a23-ece9-422b-b935-1bb1885b1b86",
   "metadata": {},
   "source": [
    "Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a656a3-b367-4bc2-8067-c6f23d6e0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "input_path = 'SCB/Sagehen_lidar/ASO/ASO_SCB_20160518/HAG/'\n",
    "output_path = 'SCB/Sagehen_lidar/ASO/ASO_SCB_20160518/corrected_tif/'\n",
    "target_val = ASO_20160518_hwy89_stats[1] # lowest 10th percentile \n",
    "correct_by_targetVal_pipeline(target_val)\n",
    "if __name__ == '__main__':\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "        full_path = [input_path + s for s in onlyfiles]\n",
    "        output_path_full = [output_path + s[:-3] +'tif' for s in onlyfiles]\n",
    "        executor.map(lidar_functions.correct_by_targetVal_rasterize, full_path, output_path_full)\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1051c8-91d9-4f5a-ac1f-264802882b41",
   "metadata": {},
   "source": [
    "# Vegetation Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a258e327-f92a-4f57-9d24-c216f1f89230",
   "metadata": {},
   "source": [
    "## Filter By Veg Strata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dc3664-957a-4333-a940-c332d1df0427",
   "metadata": {},
   "source": [
    "### [-0.15,0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64d4c4d-c510-45e1-9dc6-affc6e0a7bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_json_neg0pt15_0pt15 = json_base_path+'filter_pts_neg0pt15_0pt15.json'\n",
    "reader_dict = {'type':'readers.las'}\n",
    "filter_range_neg0pt15_0pt15 = {\"type\":\"filters.range\",\n",
    "                \"limits\":\"Z[-0.15:0.15)\"}\n",
    "writers_gdal_count= {\"type\": \"writers.gdal\",\n",
    "              'output_type': 'count',\n",
    "              'resolution': '1.0',\n",
    "              'radius': '0.7',\n",
    "              'window_size':2}\n",
    "pipeline_list = [reader_dict,filter_range_neg0pt15_0pt15,writers_gdal_count]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(range_json_neg0pt15_0pt15, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa12690-4ad8-43a2-a46e-046ccfac7adf",
   "metadata": {},
   "source": [
    "### [0.15,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9560754-966d-4adf-8976-d26d5a222a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_json_0pt15_2 = json_base_path+'filter_pts_0pt15_2.json'\n",
    "reader_dict = {'type':'readers.las'}\n",
    "filter_range_0pt15_2 = {\"type\":\"filters.range\",\n",
    "                \"limits\":\"Z[0.15:2)\"}\n",
    "writers_gdal_count= {\"type\": \"writers.gdal\",\n",
    "              'output_type': 'count',\n",
    "              'resolution': '1.0',\n",
    "              'radius': '0.7'}\n",
    "pipeline_list = [reader_dict,filter_range_0pt15_2,writers_gdal_count]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(range_json_0pt15_2, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3a1eb2-2e16-4f3e-8cdc-fc41e6b897f2",
   "metadata": {},
   "source": [
    "### [2,inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83f7a01-7547-4cf2-b995-f9f014ddb531",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_json_2 = json_base_path+'filter_pts_2.json'\n",
    "reader_dict = {'type':'readers.las'}\n",
    "filter_range_2 = {\"type\":\"filters.range\",\n",
    "                \"limits\":\"Z[2:)\"}\n",
    "writers_gdal_count= {\"type\": \"writers.gdal\",\n",
    "              'output_type': 'count',\n",
    "              'resolution': '1.0',\n",
    "              'radius': '0.7'}\n",
    "pipeline_list = [reader_dict,filter_range_2,writers_gdal_count]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(range_json_2, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82e9cdf-52e7-400a-b1cd-83f6545a1431",
   "metadata": {},
   "source": [
    "### [2,inf) Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba45046c-3404-4f71-9a5f-62254414138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_json_2_ground = json_base_path+'filter_pts_2_ground.json'\n",
    "reader_dict = {'type':'readers.las'}\n",
    "filter_range_2_ground = {\"type\":\"filters.range\",\n",
    "                \"limits\":\"Z[2:), Classification[2:2]\"}\n",
    "writers_gdal= {\"type\": \"writers.gdal\",\n",
    "              'output_type': 'count',\n",
    "              'resolution': '1.0',\n",
    "              'radius': '0.7'}\n",
    "pipeline_list = [reader_dict,filter_range_2_ground,writers_gdal]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(range_json_2_ground, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75dadba-154f-4ba3-b09f-4b0395779208",
   "metadata": {},
   "source": [
    "### [2,inf) Nonground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edae626-5fa5-48ac-98dd-87f69e8ac9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_json_2_nonground = json_base_path+'filter_pts_2_nonground.json'\n",
    "reader_dict = {'type':'readers.las'}\n",
    "filter_range_2_nonground = {\"type\":\"filters.range\",\n",
    "                \"limits\":\"Z[2:), Classification![2:2]\"}\n",
    "writers_gdal= {\"type\": \"writers.gdal\",\n",
    "              'output_type': 'count',\n",
    "              'resolution': '1.0',\n",
    "              'radius': '0.7'}\n",
    "pipeline_list = [reader_dict,filter_range_2_nonground,writers_gdal]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(range_json_2_nonground, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9a6cab-1854-4a51-8215-5658dea5f656",
   "metadata": {},
   "source": [
    "**Single File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f21ed5-5c0c-4ff1-8efd-1b9e872b6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_las = 'path/to/input/lid/filename.las'\n",
    "# output_las = 'path/to/output/lid/filename.las'\n",
    "# strata_cmd = ['pdal', 'translate', input_las,  output_las, '--json',range_json]\n",
    "# subprocess.run(strata_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ea08f-915f-472e-b622-14923d5435ea",
   "metadata": {},
   "source": [
    "**All Files in Directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edde846-02f4-4983-821a-c76e1db03cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tic = time.perf_counter()\n",
    "# pathname = \"path/to/lid/folder/\"\n",
    "# output_pathname = 'path/to/lid/folder/'\n",
    "# onlyfiles = [f for f in os.listdir(pathname) if os.path.isfile(os.path.join(pathname, f))]\n",
    "# for file in onlyfiles:\n",
    "#     input_las = pathname + file\n",
    "#     output_las = output_pathname + file\n",
    "#     strata_cmd = ['pdal', 'translate', input_las,  output_las, '--json',range_json]\n",
    "#     subprocess.run(strata_cmd)\n",
    "# toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5e266d-d3e1-460b-81af-27aeeef498c3",
   "metadata": {},
   "source": [
    "**Parallelization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7157e690-5c90-4650-bc4a-4ea8f201a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tic = time.perf_counter()\n",
    "# input_path = 'path/to/lid/folder/'\n",
    "# output_path = 'path/to/lid/folder/'\n",
    "# if __name__ == '__main__':\n",
    "#     with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "#         onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "#         full_path = [input_path + s for s in onlyfiles]\n",
    "#         output_path_full = [output_path + s for s in onlyfiles]\n",
    "#         executor.map(lidar_functions.range_json, full_path, output_path_full) #running 10 times\n",
    "# toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2890927-12f8-477e-9142-250445dd339d",
   "metadata": {},
   "source": [
    "#### Combined Pipeline Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89735f66-c4fd-43dd-9e6f-b24da0ce2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterMergeRasterize_json = json_base_path+'filterMergeRasterize_neg0pt15_0pt15.json'\n",
    "\n",
    "input_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/HAG/'\n",
    "output_tif = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/veg_classes/vegStrat_neg0pt15_0pt15.tif'\n",
    "onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "input_list = [input_path + s for s in onlyfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b27018c-0440-4685-b674-65d15dd26431",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_dict = {}\n",
    "tags = ['']*len(input_list)\n",
    "filenames = ['']*len(input_list)*2\n",
    "for i in range(len(input_list)):\n",
    "    filename_dict['filename_'+str(i)] = {'type':'readers.las','filename':input_list[i]}\n",
    "    filename_dict['filename_'+str(i)+'b'] = {\"type\":\"filters.range\",\"limits\":\"Z[-0.15,0.15)\", 'tag':'A_'+str(i)}\n",
    "    tags[i] = 'A_'+str(i)\n",
    "for j in range(len(filename_dict)):\n",
    "    filenames[j] = filename_dict[list(filename_dict)[j]]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d712e-2dec-4559-aa2a-c34ee0859cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all las files or stages\n",
    "F1 = {'type':'readers.las','filename':input_list[0]}\n",
    "R1 = {\"type\":\"filters.range\",\"limits\":\"Z[-0.15,0.15)\", 'tag':'A_0'}\n",
    "F2 = {'type':'readers.las','filename':input_list[1]}\n",
    "R2 = {\"type\":\"filters.range\",\"limits\":\"Z[-0.15,0.15)\", 'tag':'A_1'}\n",
    "\n",
    "filter_merge = {\"type\":\"filters.merge\",\n",
    "               \"tag\": \"merged\",\n",
    "               \"inputs\": ['A_0','A_1']}\n",
    "# write merged las to raster\n",
    "writers_gdal= {\"type\": \"writers.gdal\",\n",
    "               'output_type': 'count',\n",
    "              'resolution': '1.0',\n",
    "              'radius': '0.7',\n",
    "               'filename': output_tif}\n",
    "# Append each stage to a list prior to saving to json \n",
    "# pipeline_list = filenames.copy()\n",
    "# pipeline_list.append(filter_merge)\n",
    "# pipeline_list.append(writers_gdal)\n",
    "pipeline_list = [F1,R1,F2,R2,filter_merge,writers_gdal]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "# save to json\n",
    "with open(filterMergeRasterize_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d19a62-3433-4678-8fef-12e0be35ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "pdal_cmd = ['pdal','pipeline', filterMergeRasterize_json]\n",
    "subprocess.run(pdal_cmd)\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853bff0f-e7b4-48d9-9032-f9963d8832cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cb30237-5827-49ae-8b86-f6d21a02e65a",
   "metadata": {},
   "source": [
    "## Move to raster workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5d449-10d8-4292-bf09-9a9220e7e77f",
   "metadata": {},
   "source": [
    "test script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e6caa9-6398-4bf8-a45c-553e0b6fbd0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # name JSON file\n",
    "# rasterize_json = 'lidar_processing/python_scripts/PDAL_workflow/JSON/las_to_tif.json'\n",
    "# # input_las = 'lidar_processing/python_scripts/PDAL/test_las/mcc_part_b_tile_004_000.las' # define input las full file path\n",
    "# # output_las = 'lidar_processing/python_scripts/PDAL/test_las/mcc_part_b_tile_004_000_GFtutorial.las' # define input las full file path\n",
    "\n",
    "# # create a pipeline and save to a json file \n",
    "# reader_dict = {'type':'readers.las'}\n",
    "# filter_gdal= {\"type\": \"writers.gdal\",\n",
    "#               'gdaldriver':'GTiff',\n",
    "#               'output_type': 'mean',\n",
    "#               'resolution': 1.0}\n",
    "# #output_dtm = \"lidar_processing/python_scripts/PDAL/test_file/ncalm_2014_732000_4373000_DTMtutorial.tif\"\n",
    "\n",
    "\n",
    "# pipeline_list = [reader_dict,filter_gdal]\n",
    "# pipeline_dict = {'pipeline' : pipeline_list}\n",
    "# with open(rasterize_json, 'w') as out:\n",
    "#     json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71454a15-b713-4bcd-9797-5e93319d58e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# See below for better solution\n",
    "\n",
    "# pathname = \"lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/ground_filtered/NCALM/\"\n",
    "# output_pathname = \"lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/rasterize/NCALM/\"\n",
    "# onlyfiles = [f for f in os.listdir(pathname) if os.path.isfile(os.path.join(pathname, f))]\n",
    "# for file in onlyfiles:\n",
    "#     input_las = pathname + file\n",
    "#     output_las = output_pathname + file[:-4]+\".tif\"\n",
    "#     pdal_commands = ['pdal', 'translate', input_las, output_las, '--writers.gdal.resolution=1','--writers.gdal.output_type=mean']\n",
    "#     subprocess.run(pdal_commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65164a2-650a-480c-991c-a5dbc49935cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# didn't work because the pipeline wants an input/output\n",
    "\n",
    "# pathname = \"lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/ground_filtered/NCALM/\"\n",
    "# output_pathname = \"lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/rasterize/NCALM/\"\n",
    "# onlyfiles = [f for f in os.listdir(pathname) if os.path.isfile(os.path.join(pathname, f))]\n",
    "# for file in onlyfiles:\n",
    "#     input_las = pathname + file\n",
    "#     output_las = output_pathname + file[:-4]+\".tif\"\n",
    "#     pdal_commands = ['pdal', 'translate', input_las, output_las, '--json', rasterize_json]\n",
    "#     subprocess.run(pdal_commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd2d4ef-b5e5-4182-8148-d014cf3eb22b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test new formatting\n",
    "# input_las = 'lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/ground_filtered/ASO_20160417/mcc_part_b_tile_004_000.las'\n",
    "# output_las = 'lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/rasterize/ASO_20160417/mcc_part_b_tile_004_000.tif'\n",
    "# writer = '--writers.gdal.filename=lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/rasterize/ASO_20160417/mcc_part_b_tile_004_000.tif'\n",
    "# reader = '--readers.las.filename=lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/ground_filtered/ASO_20160417/mcc_part_b_tile_004_000.las'\n",
    "# rasterize_command = ['pdal', 'pipeline', 'lidar_processing/python_scripts/PDAL_workflow/JSON/las_to_tif.json', writer, reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25617c-7e4b-4c21-9337-36c2f2b9a426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test on ASO data\n",
    "# for i in [0, 1, 2, 3, 4, 5]:\n",
    "#     writer = '--writers.gdal.filename=lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/rasterize/ASO_20160518/mcc_part_b_tile_004_00'+str(i)+'.tif'\n",
    "#     reader = '--readers.las.filename=lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/ground_filtered/ASO_20160518/mcc_part_b_tile_004_00'+str(i)+'.las'\n",
    "#     rasterize_command = ['pdal', 'pipeline', 'lidar_processing/python_scripts/PDAL_workflow/JSON/las_to_tif.json', writer, reader]\n",
    "#     subprocess.run(rasterize_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb1fb84-4b06-4418-acf2-f871e4c3999f",
   "metadata": {},
   "source": [
    "### Clipping Geometries\n",
    "The goal of this portion of the code is to clip the raster based on the control areas (in the case of SCB, hwy 89)<br>\n",
    "See: https://pdal.io/tutorial/clipping/index.html#clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2abb94d-8dc7-43b6-9d5e-371d5cbbc903",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    \"autzen.laz\",\n",
    "    {\n",
    "      \"type\":\"filters.overlay\",\n",
    "      \"dimension\":\"Classification\",\n",
    "      \"datasource\":\"attributes.vrt\",\n",
    "      \"layer\":\"OGRGeoJSON\",\n",
    "      \"column\":\"CLS\"\n",
    "    },\n",
    "    {\n",
    "      \"type\":\"filters.range\",\n",
    "      \"limits\":\"Classification[5:5]\"\n",
    "    },\n",
    "    \"output.las\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b57bfb-5914-4deb-8a50-ef9d334f2d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name JSON file\n",
    "clipping_json = 'lidar_processing/python_scripts/PDAL_workflow/JSON/clip_las_to_shp.json'\n",
    "\n",
    "filter_overlay_dict = {\"type\":\"filters.overlay\",\n",
    "                       \"dimension\":\"Classification\",\n",
    "                       \"datasource\":\"SCB/bounding_box/hwy89_poly.shp\",\n",
    "                       \"column\":\"OBJECTID\"}\n",
    "filter_range_dict = {\"type\":\"filters.range\",\n",
    "                     \"limits\":\"Classification[4193:4193]\"}\n",
    "\n",
    "pipeline_list = [filter_overlay_dict,filter_range_dict]\n",
    "with open(clipping_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802830c-14f8-4a7c-be1d-194a0978bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathname = 'lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/reproject/20160518_toNAD83/toNAVD88/'\n",
    "output_pathname = \"lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/ground_filtered/ASO_20160518/reproj_NAD83_NAVD88/\"\n",
    "onlyfiles = [f for f in os.listdir(pathname) if os.path.isfile(os.path.join(pathname, f))]\n",
    "pdal_clip = ['pdal', 'translate', input_las, output_las, '--json', output_json]\n",
    "subprocess.run(pdal_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab18f5-64b2-4b50-9196-d71283014eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32043e49-150b-45e4-a858-a0e8673d6e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1f5130-70e8-42ce-bdd5-14dada2c3926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9ef7e0-3aa6-4957-a9f9-c5e87ffb963f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095da6a0-6985-4ca5-ab31-04d988240e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073fdbf1-8dce-44e1-aadc-dc77c8d83e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f880c3-1dc3-4518-ae1f-9e66cb2db0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf0361-228b-45e0-8ea9-2bf68931089d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96106e87-c47e-429a-aaf8-854ad90e8399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8450f4-2990-49ae-97d7-484b65fb4119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b1734df-2865-4acd-a92a-9613f8867044",
   "metadata": {},
   "source": [
    "# Applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371e470-c770-4b4d-93a4-52d882661c02",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019afb1c-f0f0-4e99-8072-cdabfaee5be6",
   "metadata": {},
   "source": [
    "### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caff1251-3a50-4fec-9e91-4837b39954f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input file\n",
    "input_lid = r'MRB/Merced_lidar/ASO/ASO_MRB_20210429/laz/CA_20210429_pN94S_f1_tiledlas_fl195341_ch1_ti-6720_tj-4500_ts60_v2_UTMZ11.laz'\n",
    "pdal_info_cmd = ['pdal','info',input_lid] # general info\n",
    "pdal_metadata_cmd = ['pdal','info',input_lid,'--metadata'] # full file metadata, including details crs\n",
    "subprocess.run(pdal_metadata_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ecd2f6-067f-4c0a-bba7-86442f1d6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdal_info_results = subprocess.run(pdal_metadata_cmd, stdout = subprocess.PIPE) # stout (standard out), PIPE indicates that a new pipe to the child should be created\n",
    "pdal_info_dict = json.loads(pdal_info_results.stdout.decode()) # create dict with metadata info\n",
    "#pdal_info_dict # print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb2bc9-743a-480a-9ce6-7838c8ca8be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdal_info_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4751d94d-d53d-40ce-a8d4-d62adad47b08",
   "metadata": {},
   "source": [
    "### Retile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4032e7-3646-4f0e-9d5e-acc98c7ea589",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_folder = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/NAD83_NAD83_epoch2010/'\n",
    "retile_folder = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/retile_uo/'\n",
    "onlyfiles = [f for f in os.listdir(lidar_folder) if os.path.isfile(os.path.join(lidar_folder, f))]\n",
    "for files in onlyfiles:\n",
    "    full_path = os.path.join(lidar_folder, files)\n",
    "    output_path = retile_folder+'#' + files\n",
    "    retile_command = ['pdal', 'tile', full_path, output_path, '--length=1000','--buffer=50']\n",
    "    subprocess.run(retile_command)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26292a6b-d7e1-4671-8a2c-81b27432469c",
   "metadata": {},
   "source": [
    "### Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec97e7-7e76-4572-b962-cfb692063079",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/retile_uo/730000_4364000.las'\n",
    "full_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/retile_uo/21_730000_4364000.las'\n",
    "if os.path.exists(pth):\n",
    "    lidar_folder = os.path.dirname(pth)\n",
    "    onlyfiles = [f for f in os.listdir(lidar_folder) if os.path.isfile(os.path.join(lidar_folder, f))]\n",
    "    full_paths = [os.path.join(lidar_folder, s) for s in onlyfiles] \n",
    "    full_str = ','.join(full_paths)\n",
    "    num_occurences = full_str.count(pth[:-4])\n",
    "    new_name_b = pth[:-4]+'_'+str(num_occurences)+pth[-4:]\n",
    "    os.rename(full_path, new_name_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd725789-60cb-4aa6-b79f-dfca7e1ff3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_folder = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/retile_uo/'\n",
    "tic = time.perf_counter()\n",
    "if __name__ == '__main__':\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:\n",
    "        onlyfiles = [f for f in os.listdir(lidar_folder) if os.path.isfile(os.path.join(lidar_folder, f))]\n",
    "        full_path = [os.path.join(lidar_folder, s) for s in onlyfiles]\n",
    "        executor.map(lidar_functions.rename_llx_lly_b, full_path) #running 10 times\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a97d2d1-e28e-4bed-a4ba-b0363d4434a4",
   "metadata": {},
   "source": [
    "### Save Tile Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbace8bd-7da0-4913-9960-c65f1eca84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one folder\n",
    "tic = time.perf_counter()\n",
    "lidar_folder = 'MRB/Merced_lidar/ASO/ASO_MRB_20210429/laz/'\n",
    "output_folder = 'MRB/Merced_lidar/ASO/ASO_MRB_20210429/tindex/original/'\n",
    "if __name__ == '__main__':\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        onlyfiles = [f for f in os.listdir(lidar_folder) if os.path.isfile(os.path.join(lidar_folder, f))]\n",
    "        full_path = [os.path.join(lidar_folder, s) for s in onlyfiles]\n",
    "        # change depending on directory formats\n",
    "        #output_path = [os.path.join(os.path.basename(lidar_folder),'tindex/tiles/' + s[:-3] + 'sqlite') for s in onlyfiles]\n",
    "        output_path = [output_folder + s[:-3] + 'sqlite' for s in onlyfiles]\n",
    "        executor.map(lidar_functions.create_tindex, full_path, output_path) #running 10 times\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59151d2-faa6-445f-b84a-86ecb4fa60fe",
   "metadata": {},
   "source": [
    "### Copy Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4528ffe9-6116-491e-967c-7fbfb1fdbade",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "lidar_folder = 'MRB/Merced_lidar/ASO/ASO_MRB_20210429/laz/'\n",
    "output_path = 'MRB/Merced_lidar/ASO/ASO_MRB_20210429/ICB_tiles/'\n",
    "onlyfiles = [f for f in os.listdir(lidar_folder) if os.path.isfile(os.path.join(lidar_folder, f))]\n",
    "full_paths = [os.path.join(lidar_folder, s) for s in onlyfiles] \n",
    "output_paths = np.repeat(output_path, len(full_paths))\n",
    "if __name__ == '__main__':\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        executor.map(lidar_functions.copy_lid_by_ext_ICB, full_paths, output_paths)\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b466837-460a-4f8b-9202-f81a226fa651",
   "metadata": {},
   "source": [
    "## Snow-Off Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6108329a-84f2-4009-8a79-7d1553ba633b",
   "metadata": {},
   "source": [
    "### Create DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05e3051-45c4-4ab1-8076-68fe36d1e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEM_json = json_base_path+'DEM_from_las.json' # define path to json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7b5912-904f-4064-9a78-32ac0ad932aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/NAD83_NAD83_epoch2010/'\n",
    "output_tif = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/DEM/testc_raw.tif'\n",
    "onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "input_list = [input_path + s for s in onlyfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0850ec42-97c2-4944-88b4-256f8d4dbe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_dict = {}\n",
    "tags = ['']*len(input_list)\n",
    "filenames = ['']*len(input_list)\n",
    "for i in range(len(input_list)):\n",
    "    filename_dict['filename_'+str(i)] = {'filename':input_list[i], 'tag':'A_'+str(i)}\n",
    "    tags[i] = 'A_'+str(i)\n",
    "    filenames[i] = filename_dict[list(filename_dict)[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b114ffa3-9aef-4a9c-91cb-0528a5a27d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the ground points of the tiles\n",
    "filter_range = {\"type\":\"filters.range\",\n",
    "                \"limits\":\"Classification[2:2]\"}\n",
    "# merge all las files or stages\n",
    "filter_merge = {\"type\":\"filters.merge\",\n",
    "               \"tag\": \"merged\",\n",
    "               \"inputs\": tags}\n",
    "# write merged las to raster\n",
    "writers_gdal= {\"type\": \"writers.gdal\",\n",
    "               'output_type': 'mean',\n",
    "              'resolution': '1.0',\n",
    "              'radius': '0.7',\n",
    "               'window_size':3,\n",
    "               'filename': output_tif}\n",
    "# Append each stage to a list prior to saving to json \n",
    "pipeline_list = filenames.copy()\n",
    "pipeline_list.append(filter_merge)\n",
    "pipeline_list.append(filter_range)\n",
    "pipeline_list.append(writers_gdal)\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "# save to json\n",
    "with open(DEM_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1324e2-3971-44fc-a2f8-10f60ab76ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "pdal_cmd = ['pdal','pipeline', DEM_json]\n",
    "subprocess.run(pdal_cmd)\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab111a3-7a08-4c49-8e5b-e5e9e826706d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9742452f-09d1-4952-8cc3-cc01bc0b0333",
   "metadata": {},
   "source": [
    "### Heigh Above Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c1511e-856a-426e-9794-75b704b146bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel processing\n",
    "# time = 1.1 min\n",
    "tic = time.perf_counter()\n",
    "input_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/NAD83_NAD83_epoch2010/'\n",
    "output_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/HAG/'\n",
    "if __name__ == '__main__':\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "        full_path = [input_path + s for s in onlyfiles]\n",
    "        output_path_full = [output_path  + s for s in onlyfiles]\n",
    "        executor.map(lidar_functions.HAG_dem, full_path, output_path_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa814a07-3c70-4bc8-b6d3-3b35f3336c30",
   "metadata": {},
   "source": [
    "### Vegetation Strata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127c5ddd-79bf-4db8-9cf5-bd7e84581c36",
   "metadata": {},
   "source": [
    "**Parallelization Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583388ed-8359-4773-b899-1efeb8f475e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "input_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/HAG/'\n",
    "output_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/veg_strata/vegStrat_neg0pt15_0pt15/tif/'\n",
    "if __name__ == '__main__':\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "        full_path = [input_path + s for s in onlyfiles]\n",
    "        output_path_full = [output_path + s[:-3] + 'tif' for s in onlyfiles]\n",
    "        executor.map(lidar_functions.filter_pts_neg0pt15_0pt15, full_path, output_path_full) \n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cba995-877a-4a96-a828-784ec57aade0",
   "metadata": {},
   "source": [
    "**Combined Pipeline Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d03d8-7a0f-4f32-9f9d-6848384eca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterMergeRasterize_json = json_base_path+'filterMergeRasterize_neg0pt15_0pt15.json'\n",
    "# filterMergeRasterize_json = json_base_path+'filterMergeRasterize_0pt15_2.json'\n",
    "# filterMergeRasterize_json = json_base_path+'filterMergeRasterize_2.json'\n",
    "# filterMergeRasterize_json = json_base_path+'filterMergeRasterize_2_ground.json'\n",
    "# filterMergeRasterize_json = json_base_path+'filterMergeRasterize_2_nonground.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6812bc-56a1-48d7-8efa-0f7270ecd8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/HAG/'\n",
    "output_tif = 'SCB/Sagehen_lidar/NCALM/NCALM_SCB_2014/veg_classes/vegStrat_neg0pt15_0pt15.tif'\n",
    "onlyfiles = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "input_list = [input_path + s for s in onlyfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf829acb-5f43-4303-a6fa-94f44c35a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_dict = {}\n",
    "tags = ['']*len(input_list)\n",
    "filenames = ['']*len(input_list)\n",
    "for i in range(len(input_list)):\n",
    "    filename_dict['filename_'+str(i)] = {'filename':input_list[i], 'tag':'A_'+str(i)}\n",
    "    tags[i] = 'A_'+str(i)\n",
    "    filenames[i] = filename_dict[list(filename_dict)[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4544cc-12ad-4a72-94a4-77cc4688c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the ground points of the tiles\n",
    "filter_range = {\"type\":\"filters.range\",\n",
    "                \"limits\":\"Classification[2:2]\"}\n",
    "# merge all las files or stages\n",
    "filter_merge = {\"type\":\"filters.merge\",\n",
    "               \"tag\": \"merged\",\n",
    "               \"inputs\": tags}\n",
    "# write merged las to raster\n",
    "writers_gdal= {\"type\": \"writers.gdal\",\n",
    "               'output_type': 'mean',\n",
    "              'resolution': '1.0',\n",
    "              'radius': '0.7',\n",
    "               'window_size':3,\n",
    "               'filename': output_tif}\n",
    "# Append each stage to a list prior to saving to json \n",
    "pipeline_list = filenames.copy()\n",
    "pipeline_list.append(filter_merge)\n",
    "#pipeline_list.append(filter_range)\n",
    "pipeline_list.append(writers_gdal)\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "# save to json\n",
    "with open(filterMergeRasterize_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3660945-e392-40af-84a8-84f26bb4ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "pdal_cmd = ['pdal','pipeline', filterMergeRasterize_json]\n",
    "subprocess.run(pdal_cmd)\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a658118-ad67-41a7-97e2-7d64913b8d80",
   "metadata": {},
   "source": [
    "## ____________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221a885-025a-44c5-a762-a9fdafc5a11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a4c5e-29e3-4dce-93b0-3639e61925d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c740714-5881-4763-bcb2-b2387741f477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd18c8-82e0-4a86-b878-9a53710554f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26833f00-aa67-426b-8e20-c1c3eff46862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56715656-b594-4285-9b2a-5a875aaabd01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33e66bb1-b42b-445d-af25-de4b376c9652",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf738b4-4eae-41dc-9cc8-898b177ac071",
   "metadata": {},
   "source": [
    "## File format conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be10eab7-1dc5-4561-9ff8-dbabb55abf57",
   "metadata": {},
   "source": [
    "### Convert .las to .txt\n",
    "see: https://pdal.io/stages/writers.text.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486c745d-b984-41bc-a04a-b54dcfbbaf18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069497d0-a99b-4952-bfa2-3af3d3c0ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up json file commands\n",
    "output_txt = '/Volumes/cpiske/lidar_processing/python_scripts/PDAL/test_las/mcc_part_b_tile_004_000Test.asc'\n",
    "output_json = 'lidar_processing/python_scripts/PDAL_workflow/JSON/las_to_txt.json'\n",
    "\n",
    "# create a pipeline and save to a json file \n",
    "\n",
    "filter_dict = {'type':'readers.las',\n",
    "               'override_srs': \"EPSG:4326\",\n",
    "              'filename': input_las} # we are reading in a las file\n",
    "rasterize_dict = {'type':'writers.las',\n",
    "'format':'geojson',\n",
    "'order':'X,Y,Z',\n",
    "'keep_unspecified':'false',\n",
    "'filename':output_txt}\n",
    "\n",
    "\n",
    "pipeline_list = [filter_dict, rasterize_dict]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(output_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f570972-2f18-40d1-b4d2-06f0ed5ec7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = 'lidar_processing/python_scripts/PDAL/JSON/las_to_txt.json'\n",
    "pdal_commands = ['pdal', 'pipeline', json_path]\n",
    "subprocess.run(pdal_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a3a30-1ae6-481b-96ac-f95a1f6f4ddc",
   "metadata": {},
   "source": [
    "### .laz to .las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe33f9e-84de-49ea-a538-0cd37b7f7877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # set up json file commands\n",
    "# input_laz = 'lidar_processing/python_scripts/PDAL/test_las/ASO_USCAMB20180425f1a1_180425_1_dem_filter.laz'\n",
    "# output_las = 'lidar_processing/python_scripts/PDAL/test_las/ASO_USCAMB20180425f1a1_180425_1_dem_filter.las'\n",
    "# output_json = 'lidar_processing/python_scripts/PDAL/JSON/laz_to_las.json'\n",
    "\n",
    "# # create a pipeline and save to a json file \n",
    "\n",
    "# filter_dict = {'type':'readers.las',\n",
    "#                'filename': input_las} # we are reading in a las file\n",
    "# translate_dict = {'type':'writers.las',\n",
    "#                   \"a_srs\": \"EPSG:4326\",\n",
    "#                   'filename':output_las}\n",
    "\n",
    "\n",
    "# pipeline_list = [filter_dict, translate_dict]\n",
    "# pipeline_dict = {'pipeline' : pipeline_list}\n",
    "# with open(output_json, 'w') as out:\n",
    "#     json.dump(pipeline_dict, out, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb37c88-c5d9-4859-91ab-5c35e53bd514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe40151-4f3c-4fc8-acc0-ff2e092d788b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# json_path = 'lidar_processing/python_scripts/PDAL/JSON/laz_to_las.json'\n",
    "# pdal_commands = ['pdal', 'pipeline', json_path]\n",
    "# subprocess.run(pdal_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea292cbb-156e-4be0-9fa8-62560bd55feb",
   "metadata": {},
   "source": [
    "# Raster Caluclations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b90302-4ff2-461e-84b4-28f68e90575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1,2,3,4,5]:\n",
    "    apr_elev = 'lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/rasterize/ASO_20160417/mcc_part_b_tile_004_00'+str(i)+'.tif'\n",
    "    may_elev = 'lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/rasterize/ASO_20160518/mcc_part_b_tile_004_00'+str(i)+'.tif'\n",
    "    output = 'lidar_processing/PDAL_testFiles_tutorials/test_las/SCB/raster_subtract/mcc_part_b_tile_004_00'+str(i)+'.tif'\n",
    "    raster_sub = ['gdal_calc.py', '-a', apr_elev, '-b', may_elev, '--calc=\"a - b\"', '--outfile', output]\n",
    "    subprocess.run(raster_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef95aabd-bd70-47a0-be17-993b89088961",
   "metadata": {},
   "source": [
    "# Theo Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784a85fc-2834-4d0d-81a9-19f790b08678",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_las = 'SCB/kost_lidar_data/ASO_2016/2016_05_18/WGS84_G1762_to_NAD83_NAVD88/mcc_part_b_tile_004_000.las'\n",
    "\n",
    "z_min = 0.15\n",
    "z_max = 2\n",
    "z_range = 'Z[' + str(z_min) + ':' + str(z_max) + ']'\n",
    "output_raster = 'lidar_processing/python_scripts/PDAL/test_file/mcc_part_b_tile_004_000.tif'\n",
    "output_json = 'lidar_processing/python_scripts/PDAL/JSON/las_to_tif.json'\n",
    "resolution = 0.01\n",
    "\n",
    "filter_dict = {'type':'filters.range', 'limits':z_range}\n",
    "rasterize_dict = {'filename':output_raster,\n",
    "'gdaldriver':'GTiff',\n",
    "'output_type':'count',\n",
    "'resolution':resolution,\n",
    "'type': 'writers.gdal'}\n",
    "\n",
    "\n",
    "pipeline_list = [input_las, filter_dict, rasterize_dict]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(output_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1929f364-00c7-482e-8d5f-537652eed3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_las = 'SCB/kost_lidar_data/ASO_2016/2016_05_18/WGS84_G1762_to_NAD83_NAVD88/mcc_part_b_tile_004_000.las'\n",
    "\n",
    "# z_min = 0.15\n",
    "# z_max = 2\n",
    "# z_range = 'Z[' + str(z_min) + ':' + str(z_max) + ']'\n",
    "output_raster = 'lidar_processing/python_scripts/PDAL/test_file/mcc_part_b_tile_004_000.asc'\n",
    "output_json = 'lidar_processing/python_scripts/PDAL/JSON/las_to_asc.json'\n",
    "resolution = 0.01\n",
    "\n",
    "filter_dict = {'type':'filters.range', 'limits':z_range}\n",
    "rasterize_dict = {'filename':output_raster,\n",
    "'gdaldriver':'XYZ',\n",
    "'output_type':'count',\n",
    "'resolution':resolution,\n",
    "'type': 'writers.gdal'}\n",
    "\n",
    "\n",
    "pipeline_list = [input_las, filter_dict, rasterize_dict]\n",
    "pipeline_dict = {'pipeline' : pipeline_list}\n",
    "with open(output_json, 'w') as out:\n",
    "    json.dump(pipeline_dict, out, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4f6338-edab-4c85-8941-b05d63584dd8",
   "metadata": {},
   "source": [
    "sudo docker run -v path_to_laz_folder:/input 0b pdal info /input/test.laz\n",
    "\n",
    "where path_to_laz_folder is the path to the LAS/LAZ file (you just need the folder path, not the file path).\n",
    "\n",
    ":/input is the new folder that will be created in your Docker container that will hold your point cloud.\n",
    "\n",
    "0b is just the image id of pdal\n",
    "\n",
    "/input/test.laz is the path to the point cloud in the Docker container.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a941783e-828f-4226-a25a-b772a51d12d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_laz_folder = 'lidar_processing/python_scripts/PDAL/test_las'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee8f9b-8d85-490a-a3cd-22d4b06bb646",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo docker run -v path_to_laz_folder:/input 0b pdal info /input/test.laz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac352849-3336-4cd7-b7d4-2f0c2a2c79fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import pdal\n",
    "\n",
    "def assemblePipeline(input_las, list_of_dicts):\n",
    "    pipeline_list = [input_las]\n",
    "    pipeline_list.extend(list_of_dicts)\n",
    "    pipeline_dict = {'pipeline' : pipeline_list}\n",
    "    return pipeline_dict\n",
    "\n",
    "def makeHeightFilter(height, buffer):\n",
    "    z_min = height - buffer/2\n",
    "    z_max = height + buffer/2\n",
    "    z_range = 'Z[' + str(z_min) + ':' + str(z_max) + ']'\n",
    "    heightDict = {'type':'filters.range', 'limits':z_range}\n",
    "    return heightDict\n",
    "\n",
    "def makeRasterizeFilter(output_raster, resolution, epsg):\n",
    "    rasterize_dict = {'filename':output_raster,\n",
    "                      'gdaldriver':'GTiff',\n",
    "                      'output_type':'count',\n",
    "                      'resolution':resolution,\n",
    "                      'override_srs' : epsg,\n",
    "                      'type': 'writers.gdal'}\n",
    "    return rasterize_dict\n",
    "\n",
    "def convertTifForPIL(input_raster, output_raster, epsg):\n",
    "    ''' GDAL bindings are an alien concept to me, so I gave up and used\n",
    "        subprocess.'''\n",
    "    commands = ['gdal_translate', input_raster, output_raster, '-ot', 'Byte', '-a_srs', epsg]\n",
    "    subprocess.run(commands)\n",
    "\n",
    "\n",
    "def buildHeightSlice(input_las, height, buffer, output_raster, resolution, epsg, json_path=None):\n",
    "    filter_dict = makeHeightFilter(height, buffer)\n",
    "    rasterize_dict = makeRasterizeFilter(output_raster, resolution, epsg)\n",
    "    filter_list = [filter_dict, rasterize_dict]\n",
    "    pipeline_dict = assemblePipeline(input_las, filter_list)\n",
    "\n",
    "    if json_path is not None:\n",
    "        with open(json_path, 'w') as out:\n",
    "            json.dump(pipeline_dict, out, indent=4)\n",
    "        pdal_commands = ['pdal', 'pipeline', json_path]\n",
    "        subprocess.run(pdal_commands)\n",
    "    else:\n",
    "        pdal_commands = json.dumps(pipeline_dict)\n",
    "        pipeline = pdal.Pipeline(pdal_commands)\n",
    "        pipeline.execute()\n",
    "\n",
    "input_las = '/Users/theo/data/las/TLS_0244_20180612_01_v003_30m_clip_height_norm.las'\n",
    "height = 1.37\n",
    "buffer = 0.05\n",
    "z_min = height - buffer/2\n",
    "z_max = height + buffer/2\n",
    "z_range = 'Z[' + str(z_min) + ':' + str(z_max) + ']'\n",
    "temp_raster = '/Users/theo/Pictures/almost_cool.tif'\n",
    "final_raster = '/Users/theo/Pictures/cool.tif'\n",
    "resolution = 0.01\n",
    "epsg = 'EPSG:3310'\n",
    "\n",
    "buildHeightSlice(input_las, height, buffer, temp_raster, resolution, epsg)\n",
    "convertTifForPIL(temp_raster, final_raster, epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d188910-a9a7-4c6c-b164-8a163c1d5445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import pdal\n",
    "import argparse\n",
    "\n",
    "# Create flags for the user to utilize.\n",
    "parser = argparse.ArgumentParser(description=\"Generate JSON pipeline to generate DTM from a point cloud.\")\n",
    "      \n",
    "required = parser.add_argument_group('Required arguments')\n",
    "required.add_argument('-crs', '--coordinate_system', required=True, action='store', help=\"EPSG code.\")\n",
    "required.add_argument('-i', '--infile', required=True, action='store', help=\"Input path to point cloud\")\n",
    "required.add_argument('-o', '--outfile', required=True, action='store', help=\"Output path.\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "def generateJSON(infile, list_of_dicts):\n",
    "    pipeline_list = [infile]\n",
    "    pipeline_list.extend(list_of_dicts)\n",
    "    pipeline_dict = {'pipeline': pipeline_list}\n",
    "    with open(\"pipeline.json\", 'w') as out:\n",
    "        json.dump(pipeline_dict, out, indent=4)\n",
    "\n",
    "def generateDTM(epsg, infile, outfile):\n",
    "    reproject_dict = {\"type\": \"filters.reprojection\",\n",
    "                      \"out_srs\": \"EPSG:{}\".format(epsg)}\n",
    "    reclassify_zero_dict = {\"type\": \"filters.assign\",\n",
    "                       \"assignment\": \"Classification[:]=0\"}\n",
    "    elm_dict = {\"type\": \"filters.elm\"}\n",
    "    outlier_dict = {\"type\": \"filters.outlier\"}\n",
    "    smrf_dict = {\"type\": \"filters.smrf\", \"ignore\": \"Classification[7:7]\",\n",
    "                 \"slope\": 0.2, \"window\": 16, \"threshold\": 0.45, \"scalar\": 1.2}\n",
    "    range_dict = {\"type\":\"filters.range\", \"limits\":\"Classification[2:2]\"}\n",
    "    output_dict = {\"filename\": outfile, \"gdaldriver\": \"GTiff\", \"output_type\": \"all\", \"resolution\": 0.01, \"type\": \"writers.gdal\"}\n",
    "    list_of_dicts = list([reproject_dict, reclassify_zero_dict, elm_dict, outlier_dict, smrf_dict, range_dict, output_dict])\n",
    "    generateJSON(infile, list_of_dicts)\n",
    "    pdal_cmds = ['pdal', 'pipeline', 'pipeline.json']\n",
    "    subprocess.run(pdal_cmds)\n",
    "    \n",
    "generateDTM(args.coordinate_system, args.infile, args.outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efcfb16-ecfc-4ce2-8a5e-6bf2974c4510",
   "metadata": {},
   "source": [
    "# More helpful things"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84929bbc-a6c6-49ad-bfc5-9789fe5dd577",
   "metadata": {},
   "source": [
    "### Get stats of a dataset\n",
    "see: https://www.spatialised.net/lidar-qa-with-pdal-part-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7713f5-fbfd-412c-8488-04489fa868db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name JSON file\n",
    "\n",
    "stats_json = 'lidar_processing/python_scripts/PDAL_workflow/JSON/stats.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3f4a2-adf9-4d2e-a62e-a2a538437396",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_las = {\"type\":\"readers.las\",\n",
    "              \"filename\": input_las_stats}\n",
    "filter_stats = {\"type\":\"filters.stats\",\n",
    "                \"dimensions\":\"Z\",\n",
    "                \"global\":\"Z\",\n",
    "                \"advanced\":\"true\"}\n",
    "pipeline_list = [reader_las, filter_stats]\n",
    "#pipeline_dict = {reader_las, filter_stats}\n",
    "# with open(stats_json, 'w') as out:\n",
    "#     json.dump(pipeline_dict, out, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5cfca-34a5-471d-8b40-bef477ef6438",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a58e53-92c7-47c2-b75b-f9c9466b9e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pdal.Pipeline(json.dumps(pipeline_list))\n",
    "pipeline.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722c7605-47f2-4698-bec0-f2aa20a26f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json.loads(pipeline.metadata)[\"metadata\"][\"filters.stats\"][\"statistic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c67b19a-0d9f-4b10-ad08-ccf9593fa659",
   "metadata": {},
   "source": [
    "## Navigating folders/files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67984138-2046-46f9-9187-26121ac09dca",
   "metadata": {},
   "source": [
    "**create list of files/folders with a wildcard (*)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b23dd1-01e1-46d4-81e7-b9e5be2df38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex. list all files in folder4 that end in .laz = folder1/folder2/folder3/folder4/*.laz\n",
    "# ex. list all folders named folder3 in folder 1 = foler1/*/folder3\n",
    "# ex. list all list all contents in folder2 = folder2/* - note just folder 2, no subdirectories\n",
    "glob_cmd = 'path'\n",
    "glob_exe = glob.glob(file_glob_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124af7f3-340e-4a3d-8b74-fbff724635f2",
   "metadata": {},
   "source": [
    "**create a list with all directories/subdirectories on a path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d4080-2f26-48b8-b908-992955d0200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_folders = [x[0] for x in os.walk('path')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddee80f-1c7f-46e1-a8e8-2cee82ac6f02",
   "metadata": {},
   "source": [
    "**create a list with all directories/subdirectories on a path with specific folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb7ef3c-3534-4566-9a4d-63ce9bcd074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_folders = [x[0] for x in os.walk('path')]\n",
    "index_pos_list = [ i for i in range(len(all_folders)) if all_folders[i][-6:] == 'retile' ] # must change this to meet requirements\n",
    "full_list = [all_folders[i] for i in index_pos_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507fb6c4-a80d-4b97-8533-1852b3a8e992",
   "metadata": {},
   "source": [
    "**get name of the directory just above one listed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8cc0c9-4dcb-44e7-a72f-8586c6828636",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirname = os.path.basename(os.path.dirname('path'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141720ac-a112-4891-b727-3e4999ed4298",
   "metadata": {},
   "source": [
    "**create a list with only filenames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5412acaf-9f08-430c-8ce2-ca0027d4d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in os.listdir('path') if os.path.isfile(os.path.join('path', f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d80f4b2-ebb0-4eb2-9a39-58d554be97b0",
   "metadata": {},
   "source": [
    "**create a list with full file paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc96133-4087-4aca-a90b-302487a803e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = ['path' + '/' + s for s in onlyfiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8a6064-f348-405d-bf7d-5e8c8f7bfd81",
   "metadata": {},
   "source": [
    "## Parallel Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215beb4e-46bb-4271-b452-6849510f3a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = 142.5\n",
    "tic = time.perf_counter()\n",
    "list(map(function, args));\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4ca6cc-9fb5-48ce-8146-b41150dd9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = 53 s\n",
    "tic = time.perf_counter()\n",
    "if __name__ == \"__main__\":\n",
    "    pool = Pool(3)\n",
    "    pool.map(function, arg)\n",
    "    pool.close()\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e3ba6-7d5f-4a00-b563-ee2a53074b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = very fast? .06s\n",
    "tic = time.perf_counter()\n",
    "if __name__ == \"__main__\":\n",
    "    executor = concurrent.futures.ThreadPoolExecutor(max_workers=3)\n",
    "    executor.map(function, arg)\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c6986-5a20-472a-a5bd-4a854161ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = 0.22\n",
    "tic = time.perf_counter()\n",
    "if __name__ == \"__main__\":\n",
    "    executor = concurrent.futures.ProcessPoolExecutor(max_workers=3)\n",
    "    executor.map(function, arg)\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f97306-b0c1-4b9d-8b1e-5bd95d1732c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
